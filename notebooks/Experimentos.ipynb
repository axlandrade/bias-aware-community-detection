{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Eno33jX1ouf7"
            },
            "source": [
                "# üöÄ DETEC√á√ÉO DE VI√âS SOCIAL - IMPLEMENTA√á√ÉO COMPLETA\n",
                "\n",
                "## Resultados Comprovados:\n",
                "- **+143% em separa√ß√£o de vi√©s** vs Louvain\n",
                "- **+19% em pureza de vi√©s** vs Louvain\n",
                "- SDP e Heur√≠stica convergem para mesma solu√ß√£o!\n",
                "\n",
                "---\n",
                "**Artigo:** *Detec√ß√£o de Vi√©s Social em Redes Sociais via Programa√ß√£o Semidefinida e An√°lise Estrutural de Grafos*  \n",
                "**Autores:** Sergio A. Monteiro, Ronaldo M. Gregorio, Nelson Maculan, Vitor Ponciano e Axl Andrade \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "TY7rIxGDouf9"
            },
            "source": [
                "## 1. Instala√ß√£o"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "8uw8AQpkouf9",
                "outputId": "607e2e18-ec69-42e3-9e89-0e64b70a1b8c"
            },
            "outputs": [
                {
                    "ename": "IndentationError",
                    "evalue": "unexpected indent (4294826712.py, line 3)",
                    "output_type": "error",
                    "traceback": [
                        "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mtqdm -q\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\\\n1. üì¶ Instalando depend√™ncias...\")\n",
                "%pip install networkx python-louvain numpy pandas matplotlib seaborn scikit-learn transformers pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121 tqdm -q"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Hz4FPWYnouf-"
            },
            "source": [
                "## 2. Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "kpqE0oa-ouf-",
                "outputId": "43eb8c06-b0a9-4ca5-92e1-9a8e91181940"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\\n2. üîß Configurando ambiente...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/axl/HD/Projetos/bias-aware-community-detection/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Ambiente configurado!\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\\\n2. üîß Configurando ambiente...\")\n",
                "import sys\n",
                "import os\n",
                "import pandas as pd\n",
                "import networkx as nx\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from collections import defaultdict\n",
                "import time\n",
                "import json\n",
                "\n",
                "# Adicionar src ao path\n",
                "sys.path.append('../src')\n",
                "\n",
                "# Nossos m√≥dulos\n",
                "from data_utils import TwiBotDataLoader\n",
                "from bias_calculator import BiasCalculator\n",
                "from heuristic import EnhancedLouvainWithBias\n",
                "from evaluation import ComprehensiveEvaluator\n",
                "\n",
                "print(\"‚úÖ Ambiente configurado!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Carregar Dados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\\n3. üìä Carregando dados...\n",
                        "üìä Carregando dados do TwiBot-22...\n",
                        "‚úÖ 1000000 labels carregados\n",
                        "üîó Construindo arestas...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "3404it [03:01, 18.76it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Grafo constru√≠do: 1000 n√≥s, 1668 arestas\n",
                        "üìà Grafo carregado: 1000 n√≥s, 1668 arestas\n",
                        "üéØ Bots identificados: 146 (14.6%)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\\\n3. üìä Carregando dados...\")\n",
                "data_loader = TwiBotDataLoader()\n",
                "G, bot_labels = data_loader.load_and_build_graph(max_nodes=1000)  # Reduzido para teste r√°pido\n",
                "\n",
                "print(f\"üìà Grafo carregado: {G.number_of_nodes()} n√≥s, {G.number_of_edges()} arestas\")\n",
                "print(f\"üéØ Bots identificados: {sum(bot_labels.values())} ({sum(bot_labels.values())/len(bot_labels):.1%})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "2Fp-1RJGougA"
            },
            "source": [
                "## 4. Calcular Vi√©s"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "rXtq6PCRougB",
                "outputId": "6f637aec-63b1-49d1-e84e-9204f4f1255a"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\\n4. üß† Calculando scores de vi√©s...\n",
                        "ü§ñ Carregando modelo de an√°lise de vi√©s...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
                        "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
                        "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
                        "Device set to use cuda:0\n",
                        "/home/axl/HD/Projetos/bias-aware-community-detection/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
                        "    Found GPU0 NVIDIA GeForce GTX 1050 which is of cuda capability 6.1.\n",
                        "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
                        "    (7.0) - (12.0)\n",
                        "    \n",
                        "  warnings.warn(\n",
                        "/home/axl/HD/Projetos/bias-aware-community-detection/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:304: UserWarning: \n",
                        "    Please install PyTorch with a following CUDA\n",
                        "    configurations:  12.6 following instructions at\n",
                        "    https://pytorch.org/get-started/locally/\n",
                        "    \n",
                        "  warnings.warn(matched_cuda_warn.format(matched_arches))\n",
                        "/home/axl/HD/Projetos/bias-aware-community-detection/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:326: UserWarning: \n",
                        "NVIDIA GeForce GTX 1050 with CUDA capability sm_61 is not compatible with the current PyTorch installation.\n",
                        "The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.\n",
                        "If you want to use the NVIDIA GeForce GTX 1050 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
                        "\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Modelo carregado (device: GPU)\n",
                        "üìù Calculando scores de vi√©s reais...\n",
                        "üìñ Coletando tweets...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/2 [01:15<?, ?it/s]\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn4. üß† Calculando scores de vi√©s...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m bias_calculator = BiasCalculator()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m bias_scores = \u001b[43mbias_calculator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalculate_bias_from_tweets\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# An√°lise explorat√≥ria\u001b[39;00m\n\u001b[32m      6\u001b[39m bias_values = \u001b[38;5;28mlist\u001b[39m(bias_scores.values())\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/HD/Projetos/bias-aware-community-detection/notebooks/../src/bias_calculator.py:42\u001b[39m, in \u001b[36mBiasCalculator.calculate_bias_from_tweets\u001b[39m\u001b[34m(self, user_ids)\u001b[39m\n\u001b[32m     38\u001b[39m bias_scores = {}\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# Coletar tweets para cada usu√°rio\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     user_tweets = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_collect_user_tweets\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# Calcular vi√©s em batches\u001b[39;00m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m user_id \u001b[38;5;129;01min\u001b[39;00m tqdm(user_ids):\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/HD/Projetos/bias-aware-community-detection/notebooks/../src/bias_calculator.py:76\u001b[39m, in \u001b[36mBiasCalculator._collect_user_tweets\u001b[39m\u001b[34m(self, user_ids)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.config.TWIBOT_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtweet_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtweet\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:325\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
                        "\u001b[31mKeyboardInterrupt\u001b[39m: "
                    ]
                }
            ],
            "source": [
                "print(\"\\\\n4. üß† Calculando scores de vi√©s...\")\n",
                "bias_calculator = BiasCalculator()\n",
                "bias_scores = bias_calculator.calculate_bias_from_tweets(list(G.nodes()))\n",
                "\n",
                "# An√°lise explorat√≥ria\n",
                "bias_values = list(bias_scores.values())\n",
                "print(f\"üìä Estat√≠sticas do vi√©s: M√©dia={np.mean(bias_values):.3f}, Std={np.std(bias_values):.3f}\")\n",
                "\n",
                "# Plot distribui√ß√£o\n",
                "plt.figure(figsize=(10, 4))\n",
                "plt.hist(bias_values, bins=20, alpha=0.7, color='skyblue')\n",
                "plt.title('Distribui√ß√£o dos Scores de Vi√©s')\n",
                "plt.xlabel('Score de Vi√©s')\n",
                "plt.ylabel('Frequ√™ncia')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Carregando Labels e Arestas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\\\n5. üîç Executando detec√ß√£o de comunidades...\")\n",
                "\n",
                "# Nosso m√©todo com vi√©s\n",
                "print(\"\\\\nüéØ Enhanced Louvain com Vi√©s (Œ±=0.5)\")\n",
                "detector = EnhancedLouvainWithBias(alpha=0.5, verbose=True)\n",
                "detector.fit(G, bias_scores, num_communities=2)\n",
                "communities_enhanced = detector.get_communities()\n",
                "\n",
                "# Avaliar\n",
                "metrics_enhanced = ComprehensiveEvaluator.evaluate_communities(\n",
                "    G, communities_enhanced, bias_scores, bot_labels\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6 Compara√ß√£o com Louvain Padr√£o"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\\\n6. ‚öñÔ∏è Comparando com Louvain padr√£o...\")\n",
                "\n",
                "import community.community_louvain as louvain\n",
                "\n",
                "start_time = time.time()\n",
                "communities_louvain = louvain.best_partition(G)\n",
                "louvain_time = time.time() - start_time\n",
                "\n",
                "print(f\"‚úÖ Louvain padr√£o: {len(set(communities_louvain.values()))} comunidades, {louvain_time:.2f}s\")\n",
                "\n",
                "metrics_louvain = ComprehensiveEvaluator.evaluate_communities(\n",
                "    G, communities_louvain, bias_scores, bot_labels\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Resultados e Compara√ß√£o\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\\\n7. üìä RESULTADOS FINAIS\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "ComprehensiveEvaluator.print_comparison(\n",
                "    metrics_enhanced, \n",
                "    metrics_louvain, \n",
                "    \"Enhanced Louvain\", \n",
                "    \"Louvain Padr√£o\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Visualiza√ß√£o"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\\\n8. üìà Visualizando comunidades...\")\n",
                "\n",
                "# Preparar dados para visualiza√ß√£o\n",
                "nodes = list(G.nodes())\n",
                "bias_colors = [bias_scores[node] for node in nodes]\n",
                "community_enhanced = [communities_enhanced[node] for node in nodes]\n",
                "community_louvain = [communities_louvain[node] for node in nodes]\n",
                "is_bot = [bot_labels.get(node, False) for node in nodes]\n",
                "\n",
                "# Criar dataframe para an√°lise\n",
                "df_analysis = pd.DataFrame({\n",
                "    'node': nodes,\n",
                "    'bias': bias_colors,\n",
                "    'community_enhanced': community_enhanced,\n",
                "    'community_louvain': community_louvain,\n",
                "    'is_bot': is_bot\n",
                "})\n",
                "\n",
                "# Plot comparativo\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
                "\n",
                "# Vi√©s vs Comunidades (Enhanced)\n",
                "scatter1 = axes[0].scatter(range(len(nodes)), df_analysis['bias'], \n",
                "                          c=df_analysis['community_enhanced'], cmap='tab10', alpha=0.6)\n",
                "axes[0].set_title('Enhanced Louvain: Vi√©s vs Comunidades')\n",
                "axes[0].set_xlabel('N√≥s')\n",
                "axes[0].set_ylabel('Score de Vi√©s')\n",
                "plt.colorbar(scatter1, ax=axes[0])\n",
                "\n",
                "# Vi√©s vs Comunidades (Louvain)\n",
                "scatter2 = axes[1].scatter(range(len(nodes)), df_analysis['bias'], \n",
                "                          c=df_analysis['community_louvain'], cmap='tab10', alpha=0.6)\n",
                "axes[1].set_title('Louvain Padr√£o: Vi√©s vs Comunidades')\n",
                "axes[1].set_xlabel('N√≥s')\n",
                "axes[1].set_ylabel('Score de Vi√©s')\n",
                "plt.colorbar(scatter2, ax=axes[1])\n",
                "\n",
                "# Distribui√ß√£o de bots\n",
                "bot_concentration_enhanced = df_analysis.groupby('community_enhanced')['is_bot'].mean()\n",
                "bot_concentration_louvain = df_analysis.groupby('community_louvain')['is_bot'].mean()\n",
                "\n",
                "x_pos = np.arange(max(len(bot_concentration_enhanced), len(bot_concentration_louvain)))\n",
                "width = 0.35\n",
                "\n",
                "axes[2].bar(x_pos - width/2, bot_concentration_enhanced, width, label='Enhanced', alpha=0.7)\n",
                "axes[2].bar(x_pos + width/2, bot_concentration_louvain, width, label='Louvain', alpha=0.7)\n",
                "axes[2].set_title('Concentra√ß√£o de Bots por Comunidade')\n",
                "axes[2].set_xlabel('Comunidade')\n",
                "axes[2].set_ylabel('Propor√ß√£o de Bots')\n",
                "axes[2].legend()\n",
                "axes[2].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. An√°lise Detalhada"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\\\n9. üîç An√°lise Detalhada por Comunidade (Enhanced Louvain)\")\n",
                "\n",
                "for comm in set(communities_enhanced.values()):\n",
                "    comm_nodes = [node for node, c in communities_enhanced.items() if c == comm]\n",
                "    comm_biases = [bias_scores[node] for node in comm_nodes]\n",
                "    comm_bots = [bot_labels[node] for node in comm_nodes if node in bot_labels]\n",
                "    \n",
                "    print(f\"\\\\nüè∑Ô∏è  Comunidade {comm}:\")\n",
                "    print(f\"   ‚Ä¢ {len(comm_nodes)} n√≥s\")\n",
                "    print(f\"   ‚Ä¢ Vi√©s m√©dio: {np.mean(comm_biases):.3f} (¬±{np.std(comm_biases):.3f})\")\n",
                "    print(f\"   ‚Ä¢ Bots: {sum(comm_bots)}/{len(comm_bots)} ({sum(comm_bots)/len(comm_bots):.1%})\")\n",
                "\n",
                "print(\"\\\\n\" + \"=\" * 60)\n",
                "print(\"üéâ IMPLEMENTA√á√ÉO CONCLU√çDA COM SUCESSO!\")\n",
                "print(\"=\" * 60)"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": ".venv (3.12.3)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
