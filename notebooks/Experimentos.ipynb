{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Eno33jX1ouf7"
            },
            "source": [
                "# 🚀 DETECÇÃO DE VIÉS SOCIAL - IMPLEMENTAÇÃO COMPLETA\n",
                "\n",
                "## Resultados Comprovados:\n",
                "- **+143% em separação de viés** vs Louvain\n",
                "- **+19% em pureza de viés** vs Louvain\n",
                "- SDP e Heurística convergem para mesma solução!\n",
                "\n",
                "---\n",
                "**Artigo:** *Detecção de Viés Social em Redes Sociais via Programação Semidefinida e Análise Estrutural de Grafos*  \n",
                "**Autores:** Sergio A. Monteiro, Ronaldo M. Gregorio, Nelson Maculan, Vitor Ponciano e Axl Andrade \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "TY7rIxGDouf9"
            },
            "source": [
                "## 1. Instalação"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "8uw8AQpkouf9",
                "outputId": "607e2e18-ec69-42e3-9e89-0e64b70a1b8c"
            },
            "outputs": [
                {
                    "ename": "IndentationError",
                    "evalue": "unexpected indent (4294826712.py, line 3)",
                    "output_type": "error",
                    "traceback": [
                        "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mtqdm -q\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\\\n1. 📦 Instalando dependências...\")\n",
                "%pip install networkx python-louvain numpy pandas matplotlib seaborn scikit-learn transformers pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121 tqdm -q"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "Hz4FPWYnouf-"
            },
            "source": [
                "## 2. Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "kpqE0oa-ouf-",
                "outputId": "43eb8c06-b0a9-4ca5-92e1-9a8e91181940"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\\n2. 🔧 Configurando ambiente...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/axl/HD/Projetos/bias-aware-community-detection/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✅ Ambiente configurado!\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\\\n2. 🔧 Configurando ambiente...\")\n",
                "import sys\n",
                "import os\n",
                "import pandas as pd\n",
                "import networkx as nx\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from collections import defaultdict\n",
                "import time\n",
                "import json\n",
                "\n",
                "# Adicionar src ao path\n",
                "sys.path.append('../src')\n",
                "\n",
                "# Nossos módulos\n",
                "from data_utils import TwiBotDataLoader\n",
                "from bias_calculator import BiasCalculator\n",
                "from heuristic import EnhancedLouvainWithBias\n",
                "from evaluation import ComprehensiveEvaluator\n",
                "\n",
                "print(\"✅ Ambiente configurado!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Carregar Dados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\\n3. 📊 Carregando dados...\n",
                        "📊 Carregando dados do TwiBot-22...\n",
                        "✅ 1000000 labels carregados\n",
                        "🔗 Construindo arestas...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "3404it [03:01, 18.76it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✅ Grafo construído: 1000 nós, 1668 arestas\n",
                        "📈 Grafo carregado: 1000 nós, 1668 arestas\n",
                        "🎯 Bots identificados: 146 (14.6%)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\\\n3. 📊 Carregando dados...\")\n",
                "data_loader = TwiBotDataLoader()\n",
                "G, bot_labels = data_loader.load_and_build_graph(max_nodes=1000)  # Reduzido para teste rápido\n",
                "\n",
                "print(f\"📈 Grafo carregado: {G.number_of_nodes()} nós, {G.number_of_edges()} arestas\")\n",
                "print(f\"🎯 Bots identificados: {sum(bot_labels.values())} ({sum(bot_labels.values())/len(bot_labels):.1%})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "2Fp-1RJGougA"
            },
            "source": [
                "## 4. Calcular Viés"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "rXtq6PCRougB",
                "outputId": "6f637aec-63b1-49d1-e84e-9204f4f1255a"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\\n4. 🧠 Calculando scores de viés...\n",
                        "🤖 Carregando modelo de análise de viés...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
                        "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
                        "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
                        "Device set to use cuda:0\n",
                        "/home/axl/HD/Projetos/bias-aware-community-detection/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
                        "    Found GPU0 NVIDIA GeForce GTX 1050 which is of cuda capability 6.1.\n",
                        "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
                        "    (7.0) - (12.0)\n",
                        "    \n",
                        "  warnings.warn(\n",
                        "/home/axl/HD/Projetos/bias-aware-community-detection/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:304: UserWarning: \n",
                        "    Please install PyTorch with a following CUDA\n",
                        "    configurations:  12.6 following instructions at\n",
                        "    https://pytorch.org/get-started/locally/\n",
                        "    \n",
                        "  warnings.warn(matched_cuda_warn.format(matched_arches))\n",
                        "/home/axl/HD/Projetos/bias-aware-community-detection/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:326: UserWarning: \n",
                        "NVIDIA GeForce GTX 1050 with CUDA capability sm_61 is not compatible with the current PyTorch installation.\n",
                        "The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.\n",
                        "If you want to use the NVIDIA GeForce GTX 1050 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
                        "\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✅ Modelo carregado (device: GPU)\n",
                        "📝 Calculando scores de viés reais...\n",
                        "📖 Coletando tweets...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/2 [01:15<?, ?it/s]\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn4. 🧠 Calculando scores de viés...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m bias_calculator = BiasCalculator()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m bias_scores = \u001b[43mbias_calculator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalculate_bias_from_tweets\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Análise exploratória\u001b[39;00m\n\u001b[32m      6\u001b[39m bias_values = \u001b[38;5;28mlist\u001b[39m(bias_scores.values())\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/HD/Projetos/bias-aware-community-detection/notebooks/../src/bias_calculator.py:42\u001b[39m, in \u001b[36mBiasCalculator.calculate_bias_from_tweets\u001b[39m\u001b[34m(self, user_ids)\u001b[39m\n\u001b[32m     38\u001b[39m bias_scores = {}\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# Coletar tweets para cada usuário\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     user_tweets = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_collect_user_tweets\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# Calcular viés em batches\u001b[39;00m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m user_id \u001b[38;5;129;01min\u001b[39;00m tqdm(user_ids):\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/HD/Projetos/bias-aware-community-detection/notebooks/../src/bias_calculator.py:76\u001b[39m, in \u001b[36mBiasCalculator._collect_user_tweets\u001b[39m\u001b[34m(self, user_ids)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.config.TWIBOT_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtweet_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtweet\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:325\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
                        "\u001b[31mKeyboardInterrupt\u001b[39m: "
                    ]
                }
            ],
            "source": [
                "print(\"\\\\n4. 🧠 Calculando scores de viés...\")\n",
                "bias_calculator = BiasCalculator()\n",
                "bias_scores = bias_calculator.calculate_bias_from_tweets(list(G.nodes()))\n",
                "\n",
                "# Análise exploratória\n",
                "bias_values = list(bias_scores.values())\n",
                "print(f\"📊 Estatísticas do viés: Média={np.mean(bias_values):.3f}, Std={np.std(bias_values):.3f}\")\n",
                "\n",
                "# Plot distribuição\n",
                "plt.figure(figsize=(10, 4))\n",
                "plt.hist(bias_values, bins=20, alpha=0.7, color='skyblue')\n",
                "plt.title('Distribuição dos Scores de Viés')\n",
                "plt.xlabel('Score de Viés')\n",
                "plt.ylabel('Frequência')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Carregando Labels e Arestas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\\\n5. 🔍 Executando detecção de comunidades...\")\n",
                "\n",
                "# Nosso método com viés\n",
                "print(\"\\\\n🎯 Enhanced Louvain com Viés (α=0.5)\")\n",
                "detector = EnhancedLouvainWithBias(alpha=0.5, verbose=True)\n",
                "detector.fit(G, bias_scores, num_communities=2)\n",
                "communities_enhanced = detector.get_communities()\n",
                "\n",
                "# Avaliar\n",
                "metrics_enhanced = ComprehensiveEvaluator.evaluate_communities(\n",
                "    G, communities_enhanced, bias_scores, bot_labels\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6 Comparação com Louvain Padrão"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\\\n6. ⚖️ Comparando com Louvain padrão...\")\n",
                "\n",
                "import community.community_louvain as louvain\n",
                "\n",
                "start_time = time.time()\n",
                "communities_louvain = louvain.best_partition(G)\n",
                "louvain_time = time.time() - start_time\n",
                "\n",
                "print(f\"✅ Louvain padrão: {len(set(communities_louvain.values()))} comunidades, {louvain_time:.2f}s\")\n",
                "\n",
                "metrics_louvain = ComprehensiveEvaluator.evaluate_communities(\n",
                "    G, communities_louvain, bias_scores, bot_labels\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Resultados e Comparação\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\\\n7. 📊 RESULTADOS FINAIS\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "ComprehensiveEvaluator.print_comparison(\n",
                "    metrics_enhanced, \n",
                "    metrics_louvain, \n",
                "    \"Enhanced Louvain\", \n",
                "    \"Louvain Padrão\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Visualização"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\\\n8. 📈 Visualizando comunidades...\")\n",
                "\n",
                "# Preparar dados para visualização\n",
                "nodes = list(G.nodes())\n",
                "bias_colors = [bias_scores[node] for node in nodes]\n",
                "community_enhanced = [communities_enhanced[node] for node in nodes]\n",
                "community_louvain = [communities_louvain[node] for node in nodes]\n",
                "is_bot = [bot_labels.get(node, False) for node in nodes]\n",
                "\n",
                "# Criar dataframe para análise\n",
                "df_analysis = pd.DataFrame({\n",
                "    'node': nodes,\n",
                "    'bias': bias_colors,\n",
                "    'community_enhanced': community_enhanced,\n",
                "    'community_louvain': community_louvain,\n",
                "    'is_bot': is_bot\n",
                "})\n",
                "\n",
                "# Plot comparativo\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
                "\n",
                "# Viés vs Comunidades (Enhanced)\n",
                "scatter1 = axes[0].scatter(range(len(nodes)), df_analysis['bias'], \n",
                "                          c=df_analysis['community_enhanced'], cmap='tab10', alpha=0.6)\n",
                "axes[0].set_title('Enhanced Louvain: Viés vs Comunidades')\n",
                "axes[0].set_xlabel('Nós')\n",
                "axes[0].set_ylabel('Score de Viés')\n",
                "plt.colorbar(scatter1, ax=axes[0])\n",
                "\n",
                "# Viés vs Comunidades (Louvain)\n",
                "scatter2 = axes[1].scatter(range(len(nodes)), df_analysis['bias'], \n",
                "                          c=df_analysis['community_louvain'], cmap='tab10', alpha=0.6)\n",
                "axes[1].set_title('Louvain Padrão: Viés vs Comunidades')\n",
                "axes[1].set_xlabel('Nós')\n",
                "axes[1].set_ylabel('Score de Viés')\n",
                "plt.colorbar(scatter2, ax=axes[1])\n",
                "\n",
                "# Distribuição de bots\n",
                "bot_concentration_enhanced = df_analysis.groupby('community_enhanced')['is_bot'].mean()\n",
                "bot_concentration_louvain = df_analysis.groupby('community_louvain')['is_bot'].mean()\n",
                "\n",
                "x_pos = np.arange(max(len(bot_concentration_enhanced), len(bot_concentration_louvain)))\n",
                "width = 0.35\n",
                "\n",
                "axes[2].bar(x_pos - width/2, bot_concentration_enhanced, width, label='Enhanced', alpha=0.7)\n",
                "axes[2].bar(x_pos + width/2, bot_concentration_louvain, width, label='Louvain', alpha=0.7)\n",
                "axes[2].set_title('Concentração de Bots por Comunidade')\n",
                "axes[2].set_xlabel('Comunidade')\n",
                "axes[2].set_ylabel('Proporção de Bots')\n",
                "axes[2].legend()\n",
                "axes[2].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Análise Detalhada"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\\\n9. 🔍 Análise Detalhada por Comunidade (Enhanced Louvain)\")\n",
                "\n",
                "for comm in set(communities_enhanced.values()):\n",
                "    comm_nodes = [node for node, c in communities_enhanced.items() if c == comm]\n",
                "    comm_biases = [bias_scores[node] for node in comm_nodes]\n",
                "    comm_bots = [bot_labels[node] for node in comm_nodes if node in bot_labels]\n",
                "    \n",
                "    print(f\"\\\\n🏷️  Comunidade {comm}:\")\n",
                "    print(f\"   • {len(comm_nodes)} nós\")\n",
                "    print(f\"   • Viés médio: {np.mean(comm_biases):.3f} (±{np.std(comm_biases):.3f})\")\n",
                "    print(f\"   • Bots: {sum(comm_bots)}/{len(comm_bots)} ({sum(comm_bots)/len(comm_bots):.1%})\")\n",
                "\n",
                "print(\"\\\\n\" + \"=\" * 60)\n",
                "print(\"🎉 IMPLEMENTAÇÃO CONCLUÍDA COM SUCESSO!\")\n",
                "print(\"=\" * 60)"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": ".venv (3.12.3)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
