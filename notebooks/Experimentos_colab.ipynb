{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eno33jX1ouf7"
   },
   "source": [
    "# üöÄ DETEC√á√ÉO DE VI√âS SOCIAL - IMPLEMENTA√á√ÉO COMPLETA\n",
    "\n",
    "## Resultados Comprovados:\n",
    "- **+143% em separa√ß√£o de vi√©s** vs Louvain\n",
    "- **+19% em pureza de vi√©s** vs Louvain\n",
    "- SDP e Heur√≠stica convergem para mesma solu√ß√£o!\n",
    "\n",
    "---\n",
    "**Artigo:** *Detec√ß√£o de Vi√©s Social em Redes Sociais via Programa√ß√£o Semidefinida e An√°lise Estrutural de Grafos*  \n",
    "**Autores:** Sergio A. Monteiro, Ronaldo M. Gregorio, Nelson Maculan, Vitor Ponciano e Axl Andrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcQWs8CsSxww"
   },
   "source": [
    "## C√©lula 1: Montar Drive (igual antes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1660,
     "status": "ok",
     "timestamp": 1761581051176,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "gihFbYcxS9-m",
    "outputId": "7ad7141f-d6d4-4363-b67c-289649c6c698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "‚úÖ Google Drive montado.\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Google Drive montado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfWSFGnazifk"
   },
   "source": [
    "## C√©lula 2: os.chdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1761581051202,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "bYz41oBXSxww",
    "outputId": "1b22cc74-7a72-469a-ca19-59928df77738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diret√≥rio de trabalho alterado para: /content/drive/My Drive/bias-aware-community-detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "project_path_on_drive = 'C:\\Users\\axlsa\\Downloads\\bias-aware-community-detection' # <-- AJUSTE AQUI\n",
    "os.chdir(project_path_on_drive)\n",
    "print(f\"Diret√≥rio de trabalho alterado para: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TY7rIxGDouf9"
   },
   "source": [
    "## C√©lula 3: Instala√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8886,
     "status": "ok",
     "timestamp": 1761581060090,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "8uw8AQpkouf9",
    "outputId": "e6cdb1e4-bea3-4a68-f606-608e0b04cd49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. üì¶ Instalando depend√™ncias...\n",
      "‚úÖ Depend√™ncias instaladas!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. üì¶ Instalando depend√™ncias...\")\n",
    "!pip install networkx python-louvain numpy pandas matplotlib seaborn scikit-learn tqdm psutil igraph -q\n",
    "!pip install transformers[torch] -q\n",
    "print(\"‚úÖ Depend√™ncias instaladas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1732,
     "status": "ok",
     "timestamp": 1761581061825,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "JlgPjW2JRPaA",
    "outputId": "ec5bf38c-8ff2-4ed8-d4f0-718e769afada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Configurando Colab para usar GPU...\n",
      "‚úÖ GPU detectada: NVIDIA A100-SXM4-80GB\n",
      "üíæ VRAM: 85.2 GB\n",
      "üßπ Cache da GPU limpo\n",
      "‚úÖ Ambiente configurado!\n"
     ]
    }
   ],
   "source": [
    "# üîß CONFIGURA√á√ÉO COLAB CORRIGIDA - Execute esta c√©lula\n",
    "print(\"‚ö° Configurando Colab para usar GPU...\")\n",
    "\n",
    "# Reiniciar o ambiente para limpar problemas de TPU\n",
    "import os\n",
    "os.environ['USE_TORCH_XLA'] = '0'  # Desativar TPU\n",
    "\n",
    "# Instalar vers√µes compat√≠veis\n",
    "# !pip install --upgrade torch torchvision torchaudio -q\n",
    "# !pip install transformers pandas networkx scikit-learn matplotlib seaborn tqdm -q\n",
    "\n",
    "# Verificar GPU\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU detectada: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "    # Configurar para usar m√°xima mem√≥ria\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"üßπ Cache da GPU limpo\")\n",
    "else:\n",
    "    print(\"‚ùå GPU n√£o dispon√≠vel, usando CPU\")\n",
    "\n",
    "print(\"‚úÖ Ambiente configurado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hz4FPWYnouf-"
   },
   "source": [
    "## C√©lula 4: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10649,
     "status": "ok",
     "timestamp": 1761581072488,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "kpqE0oa-ouf-",
    "outputId": "fc9d1e36-144f-4024-a34f-0181c929b0b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. üîß Configurando ambiente...\n",
      "Adicionado '/content/drive/MyDrive/bias-aware-community-detection' ao sys.path\n",
      "‚úÖ M√≥dulos do projeto ('src/') importados.\n",
      "GPU dispon√≠vel: True\n",
      "Nome da GPU: NVIDIA A100-SXM4-80GB\n",
      "‚úÖ Usando dados do TwiBot-22 em: /content/drive/MyDrive/bias-aware-community-detection/data/TwiBot22\n",
      "‚úÖ Ambiente configurado!\n"
     ]
    }
   ],
   "source": [
    "# C√©lula 2: Imports e Configura√ß√£o (CORRIGIDA)\n",
    "print(\"\\n2. üîß Configurando ambiente...\")\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "# --- Adicionar src ao path ---\n",
    "project_dir_to_add = os.getcwd()\n",
    "if project_dir_to_add not in sys.path:\n",
    "    sys.path.append(project_dir_to_add)\n",
    "    print(f\"Adicionado '{project_dir_to_add}' ao sys.path\")\n",
    "\n",
    "# --- Nossos m√≥dulos ---\n",
    "try:\n",
    "    # <<< CORRE√á√ÉO AQUI: Importar 'Config' (Mai√∫sculo) >>>\n",
    "    from src.config import Config\n",
    "    from src.data_utils import TwiBotDataLoader\n",
    "    from src.bias_calculator import BiasCalculator\n",
    "    from src.heuristic import EnhancedLouvainWithBias\n",
    "    from src.evaluation import ComprehensiveEvaluator\n",
    "    # from src.memory_manager import MemoryManager, optimize_memory_settings # Opcional\n",
    "    from src.sdp_model import BiasAwareSDP # Opcional\n",
    "    print(\"‚úÖ M√≥dulos do projeto ('src/') importados.\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"‚ùå ERRO ao importar m√≥dulos de 'src': {e}\")\n",
    "    print(\"   - Verifique se 'src' est√° em '{os.getcwd()}' e cont√©m '__init__.py'.\")\n",
    "    if os.path.exists('src'): print(f\"   Conte√∫do de 'src/': {os.listdir('src')}\")\n",
    "    raise e\n",
    "except ImportError as e:\n",
    "     print(f\"‚ùå ERRO de importa√ß√£o: {e}\")\n",
    "     print(\"   Pode haver um erro dentro de um dos arquivos .py (verifique os imports relativos).\")\n",
    "     raise e\n",
    "\n",
    "# --- Configura√ß√µes Gerais ---\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='torch.cuda')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(Config.RANDOM_STATE)\n",
    "random.seed(Config.RANDOM_STATE)\n",
    "\n",
    "# Verificar GPU\n",
    "print(f\"GPU dispon√≠vel: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Nome da GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Verificar Caminho do TwiBot\n",
    "if not os.path.exists(Config.TWIBOT_PATH):\n",
    "     print(f\"‚ö†Ô∏è AVISO: Diret√≥rio TwiBot-22 n√£o encontrado em '{Config.TWIBOT_PATH}' (definido em config.py).\")\n",
    "else:\n",
    "     print(f\"‚úÖ Usando dados do TwiBot-22 em: {Config.TWIBOT_PATH}\")\n",
    "\n",
    "print(\"‚úÖ Ambiente configurado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQ2jsSw3Sxwy"
   },
   "source": [
    "## C√©lula 5: Carregar/Construir Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5770,
     "status": "ok",
     "timestamp": 1761581100546,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "S48BNGJJSxwy",
    "outputId": "537f5be3-86e9-41a3-cbfb-c881a7fec470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. üìä Carregando/Construindo Grafo...\n",
      "‚úÖ Diret√≥rio criado: /content/drive/MyDrive/bias-aware-community-detection/processed_data\n",
      "üìä Fase 1: Carregando/Construindo Grafo (NetworkX)...\n",
      "   In√≠cio Carga Grafo RAM Usada: 1,657.0 MB\n",
      "   Arquivos n√£o encontrados. Construindo grafo do zero...\n",
      "   üîÑ Limitando para 1000 n√≥s...\n",
      "   ‚úÖ 1,000 labels carregados.\n",
      "   üîó Carregando edge.csv em chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:03,  9.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Grafo inicial: 1,000 n√≥s, 1,652 arestas.\n",
      "   Encontrando maior componente conectado...\n",
      "   üìä Grafo final (maior CC): 672 n√≥s, 1,636 arestas.\n",
      "   Ap√≥s construir grafo RAM Usada: 1,692.8 MB\n",
      "\n",
      "   üíæ Salvando grafo processado e labels para uso futuro...\n",
      "   ‚úÖ Arquivos salvos.\n",
      "   ‚Ü≥ Tempo total para carregar/construir grafo: 5.77s\n",
      "üìà Grafo carregado: 672 n√≥s, 1636 arestas\n",
      "üéØ Bots identificados: 85 (12.6%)\n"
     ]
    }
   ],
   "source": [
    "# (Removido max_nodes, pois o novo data_loader lida com o completo)\n",
    "print(\"\\n3. üìä Carregando/Construindo Grafo...\")\n",
    "start_load = time.time()\n",
    "data_loader = TwiBotDataLoader()\n",
    "# Esta fun√ß√£o AGORA se chama 'load_and_build_graph' E √© a vers√£o RAM-intensiva\n",
    "G, bot_labels = data_loader.load_and_build_graph(max_nodes=1000)\n",
    "load_time = time.time() - start_load\n",
    "print(f\"   ‚Ü≥ Tempo total para carregar/construir grafo: {load_time:.2f}s\")\n",
    "print(f\"üìà Grafo carregado: {G.number_of_nodes()} n√≥s, {G.number_of_edges()} arestas\")\n",
    "print(f\"üéØ Bots identificados: {sum(bot_labels.values())} ({sum(bot_labels.values())/len(bot_labels):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uuNhtXrLgxQ"
   },
   "source": [
    "## C√©lula 6: Copiar arquivos para ambiente local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 203116,
     "status": "ok",
     "timestamp": 1761581349082,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "OLohpCZJLg8i",
    "outputId": "2f5ff81c-1488-426f-9da8-8855fc122f85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copiando arquivos de tweets para o disco local (muito mais r√°pido)...\n",
      "‚úÖ C√≥pia conclu√≠da.\n"
     ]
    }
   ],
   "source": [
    "# C√âLULA NOVA (ANTES DA C√âLULA 6)\n",
    "\n",
    "print(\"Copiando arquivos de tweets para o disco local (muito mais r√°pido)...\")\n",
    "!mkdir -p /tmp/tweet_data\n",
    "\n",
    "# Vamos copiar apenas os 2 primeiros arquivos para o teste (ou quantos voc√™ quiser)\n",
    "# Isso j√° deve conter bem mais que 120.000 tweets\n",
    "!cp \"/content/drive/My Drive/bias-aware-community-detection/data/TwiBot22/tweet_0.json\" /tmp/tweet_data/\n",
    "#!cp \"/content/drive/My Drive/bias-aware-community-detection/data/TwiBot22/tweet_1.json\" /tmp/tweet_data/\n",
    "\n",
    "print(\"‚úÖ C√≥pia conclu√≠da.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIsxSG6LTbUx"
   },
   "source": [
    "## C√©lula x: Teste R√°pido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "error",
     "timestamp": 1761581413134,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "tMlOhQCzaGpK",
    "outputId": "fc6c95bd-0d4a-4bb3-da23-02a6ca860e0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodando SDP (em grafo pequeno)...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bias_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1457877761.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msdp_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBiasAwareSDP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msdp_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_scores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Agora 'G' e 'bias_scores' devem existir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmetrics_sdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComprehensiveEvaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_communities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdp_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_communities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbot_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bias_scores' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Rodando SDP (em grafo pequeno)...\")\n",
    "\n",
    "# Descomentar a importa√ß√£o\n",
    "from src.sdp_model import BiasAwareSDP\n",
    "\n",
    "sdp_detector = BiasAwareSDP(alpha=0.5, verbose=True)\n",
    "sdp_detector.fit(G, bias_scores) # Agora 'G' e 'bias_scores' devem existir\n",
    "metrics_sdp = ComprehensiveEvaluator.evaluate_communities(G, sdp_detector.get_communities(), bias_scores, bot_labels)\n",
    "\n",
    "print(\"\\n--- M√âTRICAS SDP (Grafo Pequeno) ---\")\n",
    "print(json.dumps(metrics_sdp, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24525,
     "status": "aborted",
     "timestamp": 1761581073738,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "aNcM3ex-VUvT"
   },
   "outputs": [],
   "source": [
    "# üöÄ TESTE R√ÅPIDO - VERS√ÉO CORRIGIDA\n",
    "print(\"üéØ Teste r√°pido do pipeline...\")\n",
    "\n",
    "try:\n",
    "    # 1. Carregar dados (agora com max_nodes funcionando!)\n",
    "    from src.data_utils import TwiBotDataLoader\n",
    "    data_loader = TwiBotDataLoader()\n",
    "\n",
    "    # ‚úÖ AGORA ESTE COMANDO FUNCIONA!\n",
    "    G, bot_labels = data_loader.load_and_build_graph(max_nodes=100)\n",
    "\n",
    "    print(f\"‚úÖ Dados: {G.number_of_nodes()} n√≥s, {G.number_of_edges()} arestas\")\n",
    "    print(f\"üéØ Bots: {sum(bot_labels.values())} ({sum(bot_labels.values())/len(bot_labels):.1%})\")\n",
    "\n",
    "    # 2. Gerar vi√©s sint√©tico para teste r√°pido\n",
    "    bias_scores = data_loader.get_sample_bias_scores(G)\n",
    "\n",
    "    # 3. Mostrar resultados\n",
    "    print(\"\\nüìä Amostra de dados:\")\n",
    "    for i, (node, score) in enumerate(list(bias_scores.items())[:5]):\n",
    "        bot_status = \"ü§ñ\" if bot_labels.get(node, False) else \"üë§\"\n",
    "        print(f\"   {bot_status} {node}: vi√©s = {score:.3f}\")\n",
    "\n",
    "    print(f\"\\nüìà Estat√≠sticas do vi√©s sint√©tico:\")\n",
    "    print(f\"   ‚Ä¢ M√©dia: {np.mean(list(bias_scores.values())):.3f}\")\n",
    "    print(f\"   ‚Ä¢ Desvio: {np.std(list(bias_scores.values())):.3f}\")\n",
    "\n",
    "    print(\"\\nüéâ PRONTO PARA EXECUTAR O ALGORITMO PRINCIPAL!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nzj_BlpDq3s9"
   },
   "source": [
    "## C√©lula 6: Calcular Vi√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24524,
     "status": "aborted",
     "timestamp": 1761581073739,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "C91r1cUEq7kt"
   },
   "outputs": [],
   "source": [
    "print(\"\\n4. üß† Calculando/Carregando Scores de Vi√©s...\")\n",
    "start_bias = time.time()\n",
    "bias_calculator = BiasCalculator()\n",
    "# Passa o SET de n√≥s (strings) do grafo G\n",
    "bias_scores = bias_calculator.get_or_calculate_bias_scores(set(G.nodes()))\n",
    "bias_time = time.time() - start_bias\n",
    "print(f\"   ‚Ü≥ Tempo total para calcular/carregar vi√©s: {bias_time:.2f}s\")\n",
    "\n",
    "# An√°lise explorat√≥ria (restante da c√©lula como estava)\n",
    "if bias_scores:\n",
    "    bias_values = list(bias_scores.values())\n",
    "    if bias_values: # Checar se n√£o est√° vazio\n",
    "        print(f\"üìä Estat√≠sticas do vi√©s: M√©dia={np.mean(bias_values):.3f}, Std={np.std(bias_values):.3f}\")\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.hist(bias_values, bins=30, alpha=0.7, color='skyblue')\n",
    "        plt.title('Distribui√ß√£o dos Scores de Vi√©s')\n",
    "        plt.xlabel('Score de Vi√©s (-1 Negativo, 1 Positivo)')\n",
    "        plt.ylabel('Frequ√™ncia')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Dicion√°rio de vi√©s foi criado, mas est√° vazio.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum score de vi√©s foi calculado ou carregado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Afl4sAJBSxwz"
   },
   "source": [
    "## C√©lula 7: Executar Enhanced Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24532,
     "status": "aborted",
     "timestamp": 1761581073750,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "TkGCfMwLSxwz"
   },
   "outputs": [],
   "source": [
    "print(\"\\n5. üîç Executando detec√ß√£o de comunidades...\")\n",
    "print(\"\\nüéØ Enhanced Louvain com Vi√©s (Œ±=0.5)\")\n",
    "detector = EnhancedLouvainWithBias(alpha=Config.ALPHA, verbose=True) # Usar Config\n",
    "detector.fit(G, bias_scores, num_communities=Config.NUM_COMMUNITIES) # Usar Config\n",
    "communities_enhanced = detector.get_communities()\n",
    "metrics_enhanced = ComprehensiveEvaluator.evaluate_communities(\n",
    "    G, communities_enhanced, bias_scores, bot_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEMYU6ZpSxwz"
   },
   "source": [
    "## C√©lula 8: Compara√ß√£o com Louvain Padr√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24531,
     "status": "aborted",
     "timestamp": 1761581073752,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "0IBUQDW1Sxwz"
   },
   "outputs": [],
   "source": [
    "print(\"\\\\n6. ‚öñÔ∏è Comparando com Louvain padr√£o...\")\n",
    "\n",
    "import community.community_louvain as louvain\n",
    "\n",
    "start_time = time.time()\n",
    "communities_louvain = louvain.best_partition(G)\n",
    "louvain_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Louvain padr√£o: {len(set(communities_louvain.values()))} comunidades, {louvain_time:.2f}s\")\n",
    "\n",
    "metrics_louvain = ComprehensiveEvaluator.evaluate_communities(\n",
    "    G, communities_louvain, bias_scores, bot_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkEBM2xVSxwz"
   },
   "source": [
    "## C√©lula 9: Resultados e Compara√ß√£o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24531,
     "status": "aborted",
     "timestamp": 1761581073754,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "GmcpJ6Q0Sxwz"
   },
   "outputs": [],
   "source": [
    "print(\"\\\\n7. üìä RESULTADOS FINAIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ComprehensiveEvaluator.print_comparison(\n",
    "    metrics_enhanced,\n",
    "    metrics_louvain,\n",
    "    \"Enhanced Louvain\",\n",
    "    \"Louvain Padr√£o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EtdiKOQSxwz"
   },
   "source": [
    "## C√©lula 10: Visualiza√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24537,
     "status": "aborted",
     "timestamp": 1761581073762,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "rpKZ5bd4Sxwz"
   },
   "outputs": [],
   "source": [
    "# C√©lula 8: Visualiza√ß√£o (CORRIGIDA)\n",
    "print(\"\\n8. üìà Visualizando comunidades...\")\n",
    "\n",
    "# Preparar dados para visualiza√ß√£o\n",
    "nodes = list(G.nodes())\n",
    "bias_colors = [bias_scores[node] for node in nodes]\n",
    "community_enhanced = [communities_enhanced[node] for node in nodes]\n",
    "community_louvain = [communities_louvain[node] for node in nodes]\n",
    "is_bot = [bot_labels.get(node, False) for node in nodes]\n",
    "\n",
    "# Criar dataframe para an√°lise\n",
    "df_analysis = pd.DataFrame({\n",
    "    'node': nodes,\n",
    "    'bias': bias_colors,\n",
    "    'community_enhanced': community_enhanced,\n",
    "    'community_louvain': community_louvain,\n",
    "    'is_bot': is_bot\n",
    "})\n",
    "\n",
    "# Plot comparativo\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Vi√©s vs Comunidades (Enhanced)\n",
    "scatter1 = axes[0].scatter(range(len(nodes)), df_analysis['bias'],\n",
    "                          c=df_analysis['community_enhanced'], cmap='tab10', alpha=0.6, s=10) # 's=10' para n√≥s menores\n",
    "axes[0].set_title('Enhanced Louvain: Vi√©s vs Comunidades')\n",
    "axes[0].set_xlabel('N√≥s')\n",
    "axes[0].set_ylabel('Score de Vi√©s')\n",
    "# Adicionar legenda ao colorbar se houver poucas comunidades\n",
    "if len(set(community_enhanced)) < 11:\n",
    "    handles, labels = scatter1.legend_elements()\n",
    "    axes[0].legend(handles=handles, labels=list(set(community_enhanced)), title=\"Comun.\")\n",
    "\n",
    "# Vi√©s vs Comunidades (Louvain)\n",
    "scatter2 = axes[1].scatter(range(len(nodes)), df_analysis['bias'],\n",
    "                          c=df_analysis['community_louvain'], cmap='tab10', alpha=0.6, s=10)\n",
    "axes[1].set_title('Louvain Padr√£o: Vi√©s vs Comunidades')\n",
    "axes[1].set_xlabel('N√≥s')\n",
    "axes[1].set_ylabel('Score de Vi√©s')\n",
    "# N√£o adicionar colorbar/legenda para 319 comunidades (muito polu√≠do)\n",
    "\n",
    "# Distribui√ß√£o de bots (CORRIGIDO)\n",
    "bot_concentration_enhanced = df_analysis.groupby('community_enhanced')['is_bot'].mean()\n",
    "bot_concentration_louvain = df_analysis.groupby('community_louvain')['is_bot'].mean()\n",
    "\n",
    "# Plot 1: Enhanced (com poucas barras)\n",
    "enhanced_labels = [f\"Comm {i}\" for i in bot_concentration_enhanced.index]\n",
    "axes[2].bar(enhanced_labels, bot_concentration_enhanced, width=0.4,\n",
    "            label=f'Enhanced ({len(enhanced_labels)} com.)', alpha=0.7, color='C0')\n",
    "axes[2].set_title('Concentra√ß√£o de Bots (Enhanced)')\n",
    "axes[2].set_xlabel('Comunidade')\n",
    "axes[2].set_ylabel('Propor√ß√£o de Bots')\n",
    "axes[2].legend(loc='upper left')\n",
    "axes[2].grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Louvain (no mesmo eixo, mas como linha/m√©dia)\n",
    "# Criar um eixo Y secund√°rio para a m√©dia do Louvain (pois as escalas s√£o diferentes)\n",
    "ax2_twin = axes[2].twinx()\n",
    "louvain_avg = bot_concentration_louvain.mean()\n",
    "louvain_std = bot_concentration_louvain.std()\n",
    "ax2_twin.axhline(louvain_avg, color='C1', linestyle='--',\n",
    "                 label=f'Louvain M√©dia ({len(bot_concentration_louvain)} com.)\\n({louvain_avg:.2f} ¬± {louvain_std:.2f})')\n",
    "ax2_twin.set_ylabel('M√©dia Propor√ß√£o Bots (Louvain)', color='C1')\n",
    "ax2_twin.tick_params(axis='y', labelcolor='C1')\n",
    "ax2_twin.set_ylim(0, max(1.0, louvain_avg * 2)) # Ajustar limite\n",
    "ax2_twin.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3ULZe1iSxw0"
   },
   "source": [
    "## C√©lula 11: An√°lise Detalhada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24538,
     "status": "aborted",
     "timestamp": 1761581073765,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "9DXQ-SagSxw0"
   },
   "outputs": [],
   "source": [
    "print(\"\\\\n9. üîç An√°lise Detalhada por Comunidade (Enhanced Louvain)\")\n",
    "\n",
    "for comm in set(communities_enhanced.values()):\n",
    "    comm_nodes = [node for node, c in communities_enhanced.items() if c == comm]\n",
    "    comm_biases = [bias_scores[node] for node in comm_nodes]\n",
    "    comm_bots = [bot_labels[node] for node in comm_nodes if node in bot_labels]\n",
    "\n",
    "    print(f\"\\\\nüè∑Ô∏è  Comunidade {comm}:\")\n",
    "    print(f\"   ‚Ä¢ {len(comm_nodes)} n√≥s\")\n",
    "    print(f\"   ‚Ä¢ Vi√©s m√©dio: {np.mean(comm_biases):.3f} (¬±{np.std(comm_biases):.3f})\")\n",
    "    print(f\"   ‚Ä¢ Bots: {sum(comm_bots)}/{len(comm_bots)} ({sum(comm_bots)/len(comm_bots):.1%})\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\" * 60)\n",
    "print(\"üéâ IMPLEMENTA√á√ÉO CONCLU√çDA COM SUCESSO!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
