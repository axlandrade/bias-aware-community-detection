{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poTB8d3Tebh3"
   },
   "source": [
    "# üöÄ Experimento Completo: Detec√ß√£o de Vi√©s no TwiBot-22\n",
    "\n",
    "Este notebook executa a pipeline completa de detec√ß√£o de vi√©s em **escala real**, conforme o artigo[cite: 1]. Ele √© otimizado para um ambiente de alta performance (Colab Pro com A100/160GB RAM).\n",
    "\n",
    "**Objetivo:** Comparar a **Heur√≠stica Corrigida (Enhanced Louvain)**  com o **Louvain Padr√£o** no dataset TwiBot-22 completo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHICIxsdebh4"
   },
   "source": [
    "## ‚öôÔ∏è Passo 0: Configura√ß√£o do Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25221,
     "status": "ok",
     "timestamp": 1761585713667,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "lbAziKJoebh4",
    "outputId": "fbd81435-bb7b-48ca-b587-529545b997ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montando Google Drive...\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMontando Google Drive...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      3\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Drive montado!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "print(\"Montando Google Drive...\")\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Drive montado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1761585714140,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "uaME3SiDebh5",
    "outputId": "40dc66ef-e945-420f-a398-11c9e1ff8478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Diret√≥rio de trabalho alterado para: e:\\Projetos\\bias-aware-community-detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ‚ÄºÔ∏è ATEN√á√ÉO: Confirme se este √© o caminho para a pasta raiz do seu projeto\n",
    "project_path_on_drive = '..'\n",
    "\n",
    "os.chdir(project_path_on_drive)\n",
    "print(f\"‚úÖ Diret√≥rio de trabalho alterado para: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7564,
     "status": "ok",
     "timestamp": 1761585721709,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "SIewlOrlebh5",
    "outputId": "da8f9aeb-496c-4952-eab4-9ff6b326eca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Instalando depend√™ncias...\n",
      "‚úÖ Depend√™ncias instaladas!\n"
     ]
    }
   ],
   "source": [
    "print(\"üì¶ Instalando depend√™ncias...\")\n",
    "!pip install networkx python-louvain pandas tqdm psutil transformers[torch] matplotlib seaborn -q\n",
    "print(\"‚úÖ Depend√™ncias instaladas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25041,
     "status": "ok",
     "timestamp": 1761585746754,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "ZLhfkd7sebh5",
    "outputId": "3c257b71-00b0-4e51-a8bf-111e10c87e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Importando m√≥dulos e configurando ambiente...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projetos\\bias-aware-community-detection\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifica√ß√£o de Hardware ---\n",
      "‚ùå GPU N√ÉO DETECTADA. Usando CPU (ser√° lento).\n",
      "‚úÖ CPUs: 12 (Config.NUM_WORKERS=2)\n",
      "‚úÖ Ambiente pronto!\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß Importando m√≥dulos e configurando ambiente...\")\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import community.community_louvain as louvain\n",
    "import warnings\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Adicionar 'src' ao sys.path para imports\n",
    "project_dir_to_add = os.getcwd()\n",
    "if project_dir_to_add not in sys.path:\n",
    "    sys.path.append(project_dir_to_add)\n",
    "\n",
    "# Importar nossos m√≥dulos\n",
    "try:\n",
    "    from src.config import Config\n",
    "    from src.data_utils import TwiBotDataLoader\n",
    "    from src.bias_calculator import BiasCalculator\n",
    "    from src.heuristic import EnhancedLouvainWithBias # A vers√£o CORRIGIDA\n",
    "    from src.evaluation import ComprehensiveEvaluator\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå ERRO: N√£o foi poss√≠vel importar os m√≥dulos. Verifique se os arquivos .py est√£o corretos e o __init__.py existe.\")\n",
    "    print(f\"Detalhe: {e}\")\n",
    "    raise e\n",
    "\n",
    "# Configura√ß√µes\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(Config.RANDOM_STATE)\n",
    "random.seed(Config.RANDOM_STATE)\n",
    "cfg = Config()\n",
    "\n",
    "# Verificar Hardware (Vital para Colab Pro)\n",
    "print(\"\\n--- Verifica√ß√£o de Hardware ---\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå GPU N√ÉO DETECTADA. Usando CPU (ser√° lento).\")\n",
    "\n",
    "print(f\"‚úÖ CPUs: {os.cpu_count()} (Config.NUM_WORKERS={cfg.NUM_WORKERS})\")\n",
    "print(\"‚úÖ Ambiente pronto!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hFyI3-jebh6"
   },
   "source": [
    "## üöÄ Passo 1: Otimiza√ß√£o de I/O (Copiar Dados para Disco Local)\n",
    "\n",
    "Esta √© a etapa **mais importante** para a velocidade. Copiamos TODOS os arquivos de tweets do Google Drive (lento) para o disco local `/tmp/` (muito r√°pido).\n",
    "\n",
    "**Esta c√©lula vai demorar alguns minutos para ser executada.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 690233,
     "status": "ok",
     "timestamp": 1761586436999,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "8VgLzxDJebh6",
    "outputId": "0ba8f8d9-c921-43b6-b968-c12f8045a84e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copiando TODOS os arquivos de tweets para o disco local (/tmp/tweet_data)...\n",
      "\n",
      "‚úÖ C√≥pia conclu√≠da em 690.22 segundos.\n",
      "Arquivos em /tmp/tweet_data: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Copiando TODOS os arquivos de tweets para o disco local (/tmp/tweet_data)...\")\n",
    "start_copy = time.time()\n",
    "\n",
    "!mkdir -p /tmp/tweet_data\n",
    "\n",
    "# Usamos o curinga '*' para copiar todos os arquivos tweet_*.json de uma vez\n",
    "!cp \"/content/drive/My Drive/bias-aware-community-detection/data/TwiBot22/tweet_0.json\" /tmp/tweet_data/\n",
    "!cp \"/content/drive/My Drive/bias-aware-community-detection/data/TwiBot22/tweet_1.json\" /tmp/tweet_data/\n",
    "!cp \"/content/drive/My Drive/bias-aware-community-detection/data/TwiBot22/tweet_2.json\" /tmp/tweet_data/\n",
    "!cp \"/content/drive/My Drive/bias-aware-community-detection/data/TwiBot22/tweet_3.json\" /tmp/tweet_data/\n",
    "\n",
    "copy_time = time.time() - start_copy\n",
    "print(f\"\\n‚úÖ C√≥pia conclu√≠da em {copy_time:.2f} segundos.\")\n",
    "print(f\"Arquivos em /tmp/tweet_data: {len(os.listdir('/tmp/tweet_data'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kc1VMTZfebh6"
   },
   "source": [
    "## üìä Passo 2: Carregar Grafo Completo (Full Scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3821132,
     "status": "ok",
     "timestamp": 1761590258132,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "aXxpJfWBebh7",
    "outputId": "59932dfb-08ef-44d5-8c09-3e172be8e2db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Carregando/Construindo Grafo (Full Scale)...\n",
      "‚úÖ Diret√≥rio criado: e:\\Projetos\\bias-aware-community-detection\\processed_data\n",
      "‚úÖ Diret√≥rio criado: e:\\Projetos\\bias-aware-community-detection\\processed_data\n",
      "üìä Fase 1: Carregando/Construindo Grafo (NetworkX)...\n",
      "   In√≠cio Carga Grafo RAM Usada: 437.1 MB\n",
      "   Arquivos encontrados! Carregando grafo e labels pr√©-processados...\n",
      "   ‚úÖ Grafo NetworkX carregado: 693,759 n√≥s, 3,301,024 arestas.\n",
      "   Ap√≥s carregar grafo RAM Usada: 1,174.2 MB\n",
      "   ‚Ü≥ Tempo total para carregar/construir grafo: 2.60s\n",
      "\n",
      "üìà Grafo Carregado: 693,759 n√≥s, 3,301,024 arestas\n",
      "üéØ Bots Identificados: 81,431 (11.7%)\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Carregando/Construindo Grafo (Full Scale)...\")\n",
    "start_load = time.time()\n",
    "\n",
    "data_loader = TwiBotDataLoader()\n",
    "\n",
    "# Garantir que os diret√≥rios de cache existem\n",
    "cfg.create_dirs()\n",
    "\n",
    "# Passar max_nodes=None para carregar o grafo inteiro\n",
    "G, bot_labels = data_loader.load_and_build_graph(max_nodes=None)\n",
    "\n",
    "load_time = time.time() - start_load\n",
    "print(f\"   ‚Ü≥ Tempo total para carregar/construir grafo: {load_time:.2f}s\")\n",
    "print(f\"\\nüìà Grafo Carregado: {G.number_of_nodes():,} n√≥s, {G.number_of_edges():,} arestas\")\n",
    "print(f\"üéØ Bots Identificados: {sum(bot_labels.values()):,} ({sum(bot_labels.values())/len(bot_labels):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebi7cQRSebh7"
   },
   "source": [
    "## üß† Passo 3: Calcular Scores de Vi√©s (Full Scale)\n",
    "\n",
    "Esta √© a etapa computacionalmente mais intensiva. Ela ir√°:\n",
    "1.  Ler os arquivos de `/tmp/` (r√°pido).\n",
    "2.  Processar **todos** os tweets relevantes (sem limite artificial).\n",
    "3.  Usar todos os seus `NUM_WORKERS` e a A100.\n",
    "\n",
    "**Esta c√©lula levar√° um tempo consider√°vel (talvez horas), mas a barra de progresso `tqdm` mostrar√° o status.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwPL9_3pebh7",
    "outputId": "72e5b9a5-fd63-4360-c88c-f1ec6d43d345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Calculando/Carregando Scores de Vi√©s (Full Scale)...\n",
      "\n",
      "üß† Fase 2: Calculando/Carregando Scores de Vi√©s...\n",
      "   In√≠cio Vi√©s RAM Usada: 1,240.1 MB\n",
      "üíæ Verificando se o arquivo final 'e:\\Projetos\\bias-aware-community-detection\\processed_data\\bias_scores.json' j√° existe...\n",
      "   Arquivo final n√£o encontrado. Calculando...\n",
      "\n",
      "--- Iniciando c√°lculo de scores de vi√©s (Single-Pass Paralelo) ---\n",
      "--- ATEN√á√ÉO: Lendo tweets do disco local: /data/TwiBot22/ ---\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] O sistema n√£o pode encontrar o caminho especificado: '/data/TwiBot22/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m bias_calculator = BiasCalculator()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Esta fun√ß√£o agora est√° configurada para ler de /tmp/ e sem TWEET_LIMIT_PER_WORKER\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m bias_scores = \u001b[43mbias_calculator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_or_calculate_bias_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m bias_time = time.time() - start_bias\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   ‚Ü≥ Tempo total para calcular/carregar vi√©s: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbias_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Projetos\\bias-aware-community-detection\\src\\bias_calculator.py:200\u001b[39m, in \u001b[36mBiasCalculator.get_or_calculate_bias_scores\u001b[39m\u001b[34m(self, G_nodes_set)\u001b[39m\n\u001b[32m    198\u001b[39m LOCAL_TWEET_PATH = \u001b[33m\"\u001b[39m\u001b[33m/data/TwiBot22/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- ATEN√á√ÉO: Lendo tweets do disco local: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLOCAL_TWEET_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m tweet_files = \u001b[38;5;28msorted\u001b[39m([f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLOCAL_TWEET_PATH\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m    201\u001b[39m                       \u001b[38;5;28;01mif\u001b[39;00m f.startswith(\u001b[33m'\u001b[39m\u001b[33mtweet_\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m f.endswith(\u001b[33m'\u001b[39m\u001b[33m.json\u001b[39m\u001b[33m'\u001b[39m)])\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# --- FIM DA MODIFICA√á√ÉO ---\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tweet_files: \n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] O sistema n√£o pode encontrar o caminho especificado: '/data/TwiBot22/'"
     ]
    }
   ],
   "source": [
    "print(\"üß† Calculando/Carregando Scores de Vi√©s (Full Scale)...\")\n",
    "start_bias = time.time()\n",
    "\n",
    "bias_calculator = BiasCalculator()\n",
    "\n",
    "# Esta fun√ß√£o agora est√° configurada para ler de /tmp/ e sem TWEET_LIMIT_PER_WORKER\n",
    "bias_scores = bias_calculator.get_or_calculate_bias_scores(set(G.nodes()))\n",
    "\n",
    "bias_time = time.time() - start_bias\n",
    "print(f\"   ‚Ü≥ Tempo total para calcular/carregar vi√©s: {bias_time:.2f}s\")\n",
    "\n",
    "# An√°lise explorat√≥ria dos scores reais\n",
    "if bias_scores:\n",
    "    bias_values = [s for s in bias_scores.values() if s != 0.0] # Ignorar n√≥s com 0.0 (sem tweets)\n",
    "    if bias_values:\n",
    "        print(f\"\\nüìä Estat√≠sticas do Vi√©s (N√≥s com tweets: {len(bias_values):,}):\")\n",
    "        print(f\"   M√©dia={np.mean(bias_values):.3f}, Std={np.std(bias_values):.3f}\")\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.hist(bias_values, bins=50, alpha=0.7, color='blue')\n",
    "        plt.title('Distribui√ß√£o dos Scores de Vi√©s (Dataset Completo)')\n",
    "        plt.xlabel('Score de Vi√©s (-1 Negativo, 1 Positivo)')\n",
    "        plt.ylabel('Frequ√™ncia')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Dicion√°rio de vi√©s foi criado, mas est√° vazio ou s√≥ cont√©m zeros.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum score de vi√©s foi calculado ou carregado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryIw7r4oebh7"
   },
   "source": [
    "## üéØ Passo 4: Executar Heur√≠stica Corrigida (Enhanced Louvain)\n",
    "\n",
    "Executamos o algoritmo principal do artigo (a heur√≠stica corrigida) , usando `alpha=0.5` [cite: 18, 217] para balancear estrutura e vi√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1E71kYIebh7"
   },
   "outputs": [],
   "source": [
    "print(f\"\\nüéØ Executando Enhanced Louvain com Vi√©s (Œ±={cfg.ALPHA})...\")\n",
    "start_enhanced = time.time()\n",
    "\n",
    "# Usar a classe HEURISTIC.PY corrigida\n",
    "detector = EnhancedLouvainWithBias(alpha=cfg.ALPHA, verbose=True)\n",
    "\n",
    "# O artigo foca em parti√ß√£o bin√°ria (k=2) [cite: 68-71, 99-106]\n",
    "detector.fit(G, bias_scores, num_communities=2)\n",
    "\n",
    "communities_enhanced = detector.get_communities()\n",
    "enhanced_time = time.time() - start_enhanced\n",
    "\n",
    "print(f\"\\n avaliando resultados da Heur√≠stica...\")\n",
    "metrics_enhanced = ComprehensiveEvaluator.evaluate_communities(\n",
    "    G, communities_enhanced, bias_scores, bot_labels\n",
    ")\n",
    "metrics_enhanced['runtime'] = enhanced_time\n",
    "\n",
    "print(f\"‚úÖ Heur√≠stica conclu√≠da em {enhanced_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTL6YVSRebh7"
   },
   "source": [
    "## ‚öñÔ∏è Passo 5: Executar Baseline (Louvain Padr√£o)\n",
    "\n",
    "Comparamos com o algoritmo de Louvain padr√£o, que otimiza apenas a modularidade (estrutura)[cite: 50]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6b6pky8ebh7"
   },
   "outputs": [],
   "source": [
    "print(\"\\n‚öñÔ∏è Executando Louvain Padr√£o (Baseline)...\")\n",
    "start_louvain = time.time()\n",
    "\n",
    "communities_louvain = louvain.best_partition(G, random_state=cfg.RANDOM_STATE)\n",
    "\n",
    "louvain_time = time.time() - start_louvain\n",
    "\n",
    "print(f\"... Louvain Padr√£o encontrou {len(set(communities_louvain.values()))} comunidades.\")\n",
    "print(\"   Avaliando resultados do Louvain Padr√£o...\")\n",
    "\n",
    "metrics_louvain = ComprehensiveEvaluator.evaluate_communities(\n",
    "    G, communities_louvain, bias_scores, bot_labels\n",
    ")\n",
    "metrics_louvain['runtime'] = louvain_time\n",
    "\n",
    "print(f\"‚úÖ Louvain Padr√£o conclu√≠do em {louvain_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnILl-B3ebh8"
   },
   "source": [
    "## üìà Passo 6: Resultados Finais e Compara√ß√£o\n",
    "\n",
    "Aqui vemos se o nosso m√©todo (Enhanced) supera o Baseline (Padr√£o) nas m√©tricas-chave do artigo: **Separa√ß√£o de Vi√©s** e **Pureza de Vi√©s** [cite: 136-138]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BtqJVAkebh8"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä RESULTADOS FINAIS (Full Scale TwiBot-22)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ComprehensiveEvaluator.print_comparison(\n",
    "    metrics_enhanced,\n",
    "    metrics_louvain,\n",
    "    \"Enhanced Louvain (Œ±=0.5)\",\n",
    "    \"Louvain Padr√£o (Œ±=0.0)\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- M√©tricas Detalhadas ---\")\n",
    "df_results = pd.DataFrame({\n",
    "    \"Enhanced Louvain (Œ±=0.5)\": metrics_enhanced,\n",
    "    \"Louvain Padr√£o (Œ±=0.0)\": metrics_louvain\n",
    "}).T\n",
    "\n",
    "print(df_results[['modularity', 'bias_separation', 'bias_purity', 'bot_concentration_max', 'num_communities', 'runtime']].to_markdown(floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTBT4v8Webh8"
   },
   "source": [
    "## üîç Passo 7: An√°lise Detalhada das Comunidades\n",
    "\n",
    "Vamos inspecionar as duas comunidades que nosso m√©todo encontrou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aufcNaRyebh8"
   },
   "outputs": [],
   "source": [
    "print(\"\\nüîç An√°lise Detalhada (Enhanced Louvain)\")\n",
    "\n",
    "comm_nodes_map = defaultdict(list)\n",
    "for node, comm in communities_enhanced.items():\n",
    "    comm_nodes_map[comm].append(node)\n",
    "\n",
    "for comm_id in sorted(comm_nodes_map.keys()):\n",
    "    comm_nodes = comm_nodes_map[comm_id]\n",
    "    comm_biases = [bias_scores.get(node, 0) for node in comm_nodes]\n",
    "    comm_bots = [bot_labels.get(node, False) for node in comm_nodes]\n",
    "\n",
    "    print(f\"\\nüè∑Ô∏è  Comunidade {comm_id}:\")\n",
    "    print(f\"   ‚Ä¢ {len(comm_nodes):,} n√≥s ({len(comm_nodes) / G.number_of_nodes():.1%})\")\n",
    "    print(f\"   ‚Ä¢ Vi√©s m√©dio: {np.mean(comm_biases):.3f} (¬±{np.std(comm_biases):.3f})\")\n",
    "    print(f\"   ‚Ä¢ Bots: {sum(comm_bots):,}/{len(comm_bots):,} ({sum(comm_bots)/len(comm_bots):.1%})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ EXPERIMENTO COMPLETO CONCLU√çDO!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
