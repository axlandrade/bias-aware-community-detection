{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poTB8d3Tebh3"
   },
   "source": [
    "# üöÄ Experimento Completo: Detec√ß√£o de Vi√©s no TwiBot-22\n",
    "\n",
    "Este notebook executa a pipeline completa de detec√ß√£o de vi√©s em **escala real**, conforme o artigo[cite: 1]. Ele √© otimizado para um ambiente de alta performance (Colab Pro com A100/160GB RAM).\n",
    "\n",
    "**Objetivo:** Comparar a **Heur√≠stica Corrigida (Enhanced Louvain)**  com o **Louvain Padr√£o** no dataset TwiBot-22 completo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHICIxsdebh4"
   },
   "source": [
    "## ‚öôÔ∏è Passo 0: Configura√ß√£o do Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1761585714140,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "uaME3SiDebh5",
    "outputId": "40dc66ef-e945-420f-a398-11c9e1ff8478"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ‚ÄºÔ∏è ATEN√á√ÉO: Confirme se este √© o caminho para a pasta raiz do seu projeto\n",
    "project_path_on_drive = '..'\n",
    "\n",
    "os.chdir(project_path_on_drive)\n",
    "print(f\"‚úÖ Diret√≥rio de trabalho alterado para: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7564,
     "status": "ok",
     "timestamp": 1761585721709,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "SIewlOrlebh5",
    "outputId": "da8f9aeb-496c-4952-eab4-9ff6b326eca6"
   },
   "outputs": [],
   "source": [
    "print(\"üì¶ Instalando depend√™ncias...\")\n",
    "!pip install networkx python-louvain pandas tqdm psutil transformers[torch] matplotlib seaborn -q\n",
    "print(\"‚úÖ Depend√™ncias instaladas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25041,
     "status": "ok",
     "timestamp": 1761585746754,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "ZLhfkd7sebh5",
    "outputId": "3c257b71-00b0-4e51-a8bf-111e10c87e27"
   },
   "outputs": [],
   "source": [
    "print(\"üîß Importando m√≥dulos e configurando ambiente...\")\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import community.community_louvain as louvain\n",
    "import warnings\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Adicionar 'src' ao sys.path para imports\n",
    "project_dir_to_add = os.getcwd()\n",
    "if project_dir_to_add not in sys.path:\n",
    "    sys.path.append(project_dir_to_add)\n",
    "\n",
    "# Importar nossos m√≥dulos\n",
    "try:\n",
    "    from src.config import Config\n",
    "    from src.data_utils import TwiBotDataLoader\n",
    "    from src.bias_calculator import BiasCalculator\n",
    "    from src.heuristic import EnhancedLouvainWithBias # A vers√£o CORRIGIDA\n",
    "    from src.evaluation import ComprehensiveEvaluator\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå ERRO: N√£o foi poss√≠vel importar os m√≥dulos. Verifique se os arquivos .py est√£o corretos e o __init__.py existe.\")\n",
    "    print(f\"Detalhe: {e}\")\n",
    "    raise e\n",
    "\n",
    "# Configura√ß√µes\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(Config.RANDOM_STATE)\n",
    "random.seed(Config.RANDOM_STATE)\n",
    "cfg = Config()\n",
    "\n",
    "# Verificar Hardware (Vital para Colab Pro)\n",
    "print(\"\\n--- Verifica√ß√£o de Hardware ---\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå GPU N√ÉO DETECTADA. Usando CPU (ser√° lento).\")\n",
    "\n",
    "print(f\"‚úÖ CPUs: {os.cpu_count()} (Config.NUM_WORKERS={cfg.NUM_WORKERS})\")\n",
    "print(\"‚úÖ Ambiente pronto!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hFyI3-jebh6"
   },
   "source": [
    "## üöÄ Passo 1: Otimiza√ß√£o de I/O (Copiar Dados para Disco Local)\n",
    "\n",
    "Esta √© a etapa **mais importante** para a velocidade. Copiamos TODOS os arquivos de tweets do Google Drive (lento) para o disco local `/tmp/` (muito r√°pido).\n",
    "\n",
    "**Esta c√©lula vai demorar alguns minutos para ser executada.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 690233,
     "status": "ok",
     "timestamp": 1761586436999,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "8VgLzxDJebh6",
    "outputId": "0ba8f8d9-c921-43b6-b968-c12f8045a84e"
   },
   "outputs": [],
   "source": [
    "print(\"Copiando TODOS os arquivos de tweets para o disco local (/tmp/tweet_data)...\")\n",
    "start_copy = time.time()\n",
    "\n",
    "!mkdir -p /tmp/tweet_data\n",
    "\n",
    "# Usamos o curinga '*' para copiar todos os arquivos tweet_*.json de uma vez\n",
    "!cp \"/content/drive/My Drive/bias-aware-community-detection/data/TwiBot22/tweet_0.json\" /tmp/tweet_data/\n",
    "!cp \"/content/drive/My Drive/bias-aware-community-detection/data/TwiBot22/tweet_1.json\" /tmp/tweet_data/\n",
    "!cp \"/content/drive/My Drive/bias-aware-community-detection/data/TwiBot22/tweet_2.json\" /tmp/tweet_data/\n",
    "!cp \"/content/drive/My Drive/bias-aware-community-detection/data/TwiBot22/tweet_3.json\" /tmp/tweet_data/\n",
    "\n",
    "copy_time = time.time() - start_copy\n",
    "print(f\"\\n‚úÖ C√≥pia conclu√≠da em {copy_time:.2f} segundos.\")\n",
    "print(f\"Arquivos em /tmp/tweet_data: {len(os.listdir('/tmp/tweet_data'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kc1VMTZfebh6"
   },
   "source": [
    "## üìä Passo 2: Carregar Grafo Completo (Full Scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3821132,
     "status": "ok",
     "timestamp": 1761590258132,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "aXxpJfWBebh7",
    "outputId": "59932dfb-08ef-44d5-8c09-3e172be8e2db"
   },
   "outputs": [],
   "source": [
    "print(\"üìä Carregando/Construindo Grafo (Full Scale)...\")\n",
    "start_load = time.time()\n",
    "\n",
    "data_loader = TwiBotDataLoader()\n",
    "\n",
    "# Garantir que os diret√≥rios de cache existem\n",
    "cfg.create_dirs()\n",
    "\n",
    "# Passar max_nodes=None para carregar o grafo inteiro\n",
    "G, bot_labels = data_loader.load_and_build_graph(max_nodes=None)\n",
    "\n",
    "load_time = time.time() - start_load\n",
    "print(f\"   ‚Ü≥ Tempo total para carregar/construir grafo: {load_time:.2f}s\")\n",
    "print(f\"\\nüìà Grafo Carregado: {G.number_of_nodes():,} n√≥s, {G.number_of_edges():,} arestas\")\n",
    "print(f\"üéØ Bots Identificados: {sum(bot_labels.values()):,} ({sum(bot_labels.values())/len(bot_labels):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebi7cQRSebh7"
   },
   "source": [
    "## üß† Passo 3: Calcular Scores de Vi√©s (Full Scale)\n",
    "\n",
    "Esta √© a etapa computacionalmente mais intensiva. Ela ir√°:\n",
    "1.  Ler os arquivos de `/tmp/` (r√°pido).\n",
    "2.  Processar **todos** os tweets relevantes (sem limite artificial).\n",
    "3.  Usar todos os seus `NUM_WORKERS` e a A100.\n",
    "\n",
    "**Esta c√©lula levar√° um tempo consider√°vel (talvez horas), mas a barra de progresso `tqdm` mostrar√° o status.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwPL9_3pebh7",
    "outputId": "72e5b9a5-fd63-4360-c88c-f1ec6d43d345"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "print(\"üß† Calculando/Carregando Scores de Vi√©s (Full Scale)...\")\n",
    "start_bias = time.time()\n",
    "\n",
    "bias_calculator = BiasCalculator()\n",
    "\n",
    "# Esta fun√ß√£o agora est√° configurada para ler de /tmp/ e sem TWEET_LIMIT_PER_WORKER\n",
    "bias_scores = bias_calculator.get_or_calculate_bias_scores(set(G.nodes()))\n",
    "\n",
    "bias_time = time.time() - start_bias\n",
    "print(f\"   ‚Ü≥ Tempo total para calcular/carregar vi√©s: {bias_time:.2f}s\")\n",
    "\n",
    "# An√°lise explorat√≥ria dos scores reais\n",
    "if bias_scores:\n",
    "    bias_values = [s for s in bias_scores.values() if s != 0.0] # Ignorar n√≥s com 0.0 (sem tweets)\n",
    "    if bias_values:\n",
    "        print(f\"\\nüìä Estat√≠sticas do Vi√©s (N√≥s com tweets: {len(bias_values):,}):\")\n",
    "        print(f\"   M√©dia={np.mean(bias_values):.3f}, Std={np.std(bias_values):.3f}\")\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.hist(bias_values, bins=50, alpha=0.7, color='blue')\n",
    "        plt.title('Distribui√ß√£o dos Scores de Vi√©s (Dataset Completo)')\n",
    "        plt.xlabel('Score de Vi√©s (-1 Negativo, 1 Positivo)')\n",
    "        plt.ylabel('Frequ√™ncia')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Dicion√°rio de vi√©s foi criado, mas est√° vazio ou s√≥ cont√©m zeros.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum score de vi√©s foi calculado ou carregado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryIw7r4oebh7"
   },
   "source": [
    "## üéØ Passo 4: Executar Heur√≠stica Corrigida (Enhanced Louvain)\n",
    "\n",
    "Executamos o algoritmo principal do artigo (a heur√≠stica corrigida) , usando `alpha=0.5` [cite: 18, 217] para balancear estrutura e vi√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1E71kYIebh7"
   },
   "outputs": [],
   "source": [
    "print(f\"\\nüéØ Executando Enhanced Louvain com Vi√©s (Œ±={cfg.ALPHA})...\")\n",
    "start_enhanced = time.time()\n",
    "\n",
    "# Usar a classe HEURISTIC.PY corrigida\n",
    "detector = EnhancedLouvainWithBias(alpha=cfg.ALPHA, verbose=True)\n",
    "\n",
    "# O artigo foca em parti√ß√£o bin√°ria (k=2) [cite: 68-71, 99-106]\n",
    "detector.fit(G, bias_scores, num_communities=2)\n",
    "\n",
    "communities_enhanced = detector.get_communities()\n",
    "enhanced_time = time.time() - start_enhanced\n",
    "\n",
    "print(f\"\\n avaliando resultados da Heur√≠stica...\")\n",
    "metrics_enhanced = ComprehensiveEvaluator.evaluate_communities(\n",
    "    G, communities_enhanced, bias_scores, bot_labels\n",
    ")\n",
    "metrics_enhanced['runtime'] = enhanced_time\n",
    "\n",
    "print(f\"‚úÖ Heur√≠stica conclu√≠da em {enhanced_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTL6YVSRebh7"
   },
   "source": [
    "## ‚öñÔ∏è Passo 5: Executar Baseline (Louvain Padr√£o)\n",
    "\n",
    "Comparamos com o algoritmo de Louvain padr√£o, que otimiza apenas a modularidade (estrutura)[cite: 50]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6b6pky8ebh7"
   },
   "outputs": [],
   "source": [
    "print(\"\\n‚öñÔ∏è Executando Louvain Padr√£o (Baseline)...\")\n",
    "start_louvain = time.time()\n",
    "\n",
    "communities_louvain = louvain.best_partition(G, random_state=cfg.RANDOM_STATE)\n",
    "\n",
    "louvain_time = time.time() - start_louvain\n",
    "\n",
    "print(f\"... Louvain Padr√£o encontrou {len(set(communities_louvain.values()))} comunidades.\")\n",
    "print(\"   Avaliando resultados do Louvain Padr√£o...\")\n",
    "\n",
    "metrics_louvain = ComprehensiveEvaluator.evaluate_communities(\n",
    "    G, communities_louvain, bias_scores, bot_labels\n",
    ")\n",
    "metrics_louvain['runtime'] = louvain_time\n",
    "\n",
    "print(f\"‚úÖ Louvain Padr√£o conclu√≠do em {louvain_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnILl-B3ebh8"
   },
   "source": [
    "## üìà Passo 6: Resultados Finais e Compara√ß√£o\n",
    "\n",
    "Aqui vemos se o nosso m√©todo (Enhanced) supera o Baseline (Padr√£o) nas m√©tricas-chave do artigo: **Separa√ß√£o de Vi√©s** e **Pureza de Vi√©s** [cite: 136-138]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BtqJVAkebh8"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä RESULTADOS FINAIS (Full Scale TwiBot-22)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ComprehensiveEvaluator.print_comparison(\n",
    "    metrics_enhanced,\n",
    "    metrics_louvain,\n",
    "    \"Enhanced Louvain (Œ±=0.5)\",\n",
    "    \"Louvain Padr√£o (Œ±=0.0)\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- M√©tricas Detalhadas ---\")\n",
    "df_results = pd.DataFrame({\n",
    "    \"Enhanced Louvain (Œ±=0.5)\": metrics_enhanced,\n",
    "    \"Louvain Padr√£o (Œ±=0.0)\": metrics_louvain\n",
    "}).T\n",
    "\n",
    "print(df_results[['modularity', 'bias_separation', 'bias_purity', 'bot_concentration_max', 'num_communities', 'runtime']].to_markdown(floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTBT4v8Webh8"
   },
   "source": [
    "## üîç Passo 7: An√°lise Detalhada das Comunidades\n",
    "\n",
    "Vamos inspecionar as duas comunidades que nosso m√©todo encontrou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aufcNaRyebh8"
   },
   "outputs": [],
   "source": [
    "print(\"\\nüîç An√°lise Detalhada (Enhanced Louvain)\")\n",
    "\n",
    "comm_nodes_map = defaultdict(list)\n",
    "for node, comm in communities_enhanced.items():\n",
    "    comm_nodes_map[comm].append(node)\n",
    "\n",
    "for comm_id in sorted(comm_nodes_map.keys()):\n",
    "    comm_nodes = comm_nodes_map[comm_id]\n",
    "    comm_biases = [bias_scores.get(node, 0) for node in comm_nodes]\n",
    "    comm_bots = [bot_labels.get(node, False) for node in comm_nodes]\n",
    "\n",
    "    print(f\"\\nüè∑Ô∏è  Comunidade {comm_id}:\")\n",
    "    print(f\"   ‚Ä¢ {len(comm_nodes):,} n√≥s ({len(comm_nodes) / G.number_of_nodes():.1%})\")\n",
    "    print(f\"   ‚Ä¢ Vi√©s m√©dio: {np.mean(comm_biases):.3f} (¬±{np.std(comm_biases):.3f})\")\n",
    "    print(f\"   ‚Ä¢ Bots: {sum(comm_bots):,}/{len(comm_bots):,} ({sum(comm_bots)/len(comm_bots):.1%})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ EXPERIMENTO COMPLETO CONCLU√çDO!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
