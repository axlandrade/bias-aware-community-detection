{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poTB8d3Tebh3"
   },
   "source": [
    "\n",
    "# üöÄ Experimento Completo: Detec√ß√£o de Vi√©s no TwiBot-22\n",
    "\n",
    "Este notebook executa a pipeline completa de detec√ß√£o de vi√©s em **escala real**, conforme o artigo[cite: 1]. Ele √© otimizado para um ambiente de alta performance (Colab Pro com A100/160GB RAM).\n",
    "\n",
    "**Objetivo:** Comparar a **Heur√≠stica Corrigida (Enhanced Louvain)**  com o **Louvain Padr√£o** no dataset TwiBot-22 completo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHICIxsdebh4"
   },
   "source": [
    "## ‚öôÔ∏è Passo 0: Configura√ß√£o do Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1761585714140,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "uaME3SiDebh5",
    "outputId": "40dc66ef-e945-420f-a398-11c9e1ff8478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Diret√≥rio de trabalho alterado para: c:\\Users\\axlsa\\Documents\\bias-aware-community-detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ‚ÄºÔ∏è ATEN√á√ÉO: Confirme se este √© o caminho para a pasta raiz do seu projeto\n",
    "project_path_on_drive = '..'\n",
    "\n",
    "os.chdir(project_path_on_drive)\n",
    "print(f\"‚úÖ Diret√≥rio de trabalho alterado para: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7564,
     "status": "ok",
     "timestamp": 1761585721709,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "SIewlOrlebh5",
    "outputId": "da8f9aeb-496c-4952-eab4-9ff6b326eca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Instalando depend√™ncias...\n",
      "   Atualizando pip...\n",
      "   Instalando PyTorch (CUDA)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: To modify pip, please run the following command:\n",
      "c:\\Users\\axlsa\\Documents\\bias-aware-community-detection\\.venv\\Scripts\\python.exe -m pip install --upgrade pip -q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu130\n",
      "Requirement already satisfied: torch in c:\\users\\axlsa\\documents\\bias-aware-community-detection\\.venv\\lib\\site-packages (2.9.0+cu130)\n",
      "Requirement already satisfied: torchvision in c:\\users\\axlsa\\documents\\bias-aware-community-detection\\.venv\\lib\\site-packages (0.24.0+cu130)\n",
      "Requirement already satisfied: filelock in c:\\users\\axlsa\\documents\\bias-aware-community-detection\\.venv\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\axlsa\\documents\\bias-aware-community-detection\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\axlsa\\documents\\bias-aware-community-detection\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\axlsa\\documents\\bias-aware-community-detection\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\axlsa\\documents\\bias-aware-community-detection\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\axlsa\\documents\\bias-aware-community-detection\\.venv\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\axlsa\\documents\\bias-aware-community-detection\\.venv\\lib\\site-packages (from torch) (70.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\axlsa\\documents\\bias-aware-community-detection\\.venv\\lib\\site-packages (from torchvision) (2.3.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\axlsa\\documents\\bias-aware-community-detection\\.venv\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\axlsa\\documents\\bias-aware-community-detection\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\axlsa\\documents\\bias-aware-community-detection\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "   Instalando networkx, pandas, transformers, etc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Depend√™ncias instaladas!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "print(\"üì¶ Instalando depend√™ncias...\")\n",
    "\n",
    "# Passo 0: Atualizar pip\n",
    "print(\"   Atualizando pip...\")\n",
    "!pip install --upgrade pip -q\n",
    "\n",
    "# Passo 1: Instalar PyTorch (com CUDA) usando o URL especial\n",
    "print(\"   Instalando PyTorch (CUDA)...\")\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu130\n",
    "\n",
    "# Passo 2: Instalar as outras bibliotecas (do reposit√≥rio padr√£o)\n",
    "print(\"   Instalando networkx, pandas, transformers, etc...\")\n",
    "!pip install ipywidgets scikit-learn networkx python-louvain pandas tqdm psutil transformers[torch] matplotlib seaborn -q\n",
    "\n",
    "print(\"‚úÖ Depend√™ncias instaladas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25041,
     "status": "ok",
     "timestamp": 1761585746754,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "ZLhfkd7sebh5",
    "outputId": "3c257b71-00b0-4e51-a8bf-111e10c87e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Importando m√≥dulos e configurando ambiente...\n",
      "\n",
      "--- Verifica√ß√£o de Hardware (Local) ---\n",
      "‚úÖ GPU: NVIDIA GeForce RTX 3060\n",
      "   VRAM: 12.9 GB\n",
      "‚úÖ CPUs: 12 (Config.NUM_WORKERS=12)\n",
      "‚úÖ Ambiente local pronto!\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß Importando m√≥dulos e configurando ambiente...\")\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import community.community_louvain as louvain\n",
    "import warnings\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Adicionar 'src' ao sys.path para imports\n",
    "project_dir_to_add = os.getcwd()\n",
    "if project_dir_to_add not in sys.path:\n",
    "    sys.path.append(project_dir_to_add)\n",
    "\n",
    "# Importar nossos m√≥dulos\n",
    "try:\n",
    "    from src.config import Config\n",
    "    from src.data_utils import TwiBotDataLoader\n",
    "    from src.bias_calculator import BiasCalculator\n",
    "    from src.heuristic import EnhancedLouvainWithBias # A vers√£o CORRIGIDA\n",
    "    from src.evaluation import ComprehensiveEvaluator\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå ERRO: N√£o foi poss√≠vel importar os m√≥dulos. Verifique se os arquivos .py est√£o corretos e o __init__.py existe.\")\n",
    "    print(f\"Detalhe: {e}\")\n",
    "    raise e\n",
    "\n",
    "# Configura√ß√µes\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(Config.RANDOM_STATE)\n",
    "random.seed(Config.RANDOM_STATE)\n",
    "cfg = Config()\n",
    "\n",
    "# --- Verifica√ß√£o de Hardware (Ambiente Local Windows 11) ---\n",
    "print(\"\\n--- Verifica√ß√£o de Hardware (Local) ---\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå GPU NVIDIA (CUDA) N√ÉO DETECTADA. Usando CPU (ser√° lento).\")\n",
    "\n",
    "# cfg foi definido na c√©lula anterior (cfg = Config())\n",
    "print(f\"‚úÖ CPUs: {os.cpu_count()} (Config.NUM_WORKERS={cfg.NUM_WORKERS})\")\n",
    "print(\"‚úÖ Ambiente local pronto!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kc1VMTZfebh6"
   },
   "source": [
    "## üìä Passo 2: Carregar Grafo Completo (Full Scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3821132,
     "status": "ok",
     "timestamp": 1761590258132,
     "user": {
      "displayName": "Axl Andrade",
      "userId": "05906505906187169759"
     },
     "user_tz": 180
    },
    "id": "aXxpJfWBebh7",
    "outputId": "59932dfb-08ef-44d5-8c09-3e172be8e2db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Carregando/Construindo Grafo (Full Scale)...\n",
      "‚úÖ Diret√≥rio criado: c:\\Users\\axlsa\\Documents\\bias-aware-community-detection\\processed_data\n",
      "‚úÖ Diret√≥rio criado: c:\\Users\\axlsa\\Documents\\bias-aware-community-detection\\processed_data\n",
      "üìä Fase 1: Carregando/Construindo Grafo (NetworkX)...\n",
      "   In√≠cio Carga Grafo RAM Usada: 763.8 MB\n",
      "   Arquivos n√£o encontrados. Construindo grafo do zero...\n",
      "   ‚úÖ 1,000,000 labels carregados.\n",
      "   üîó Carregando edge.csv em chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1702it [33:24,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Grafo inicial: 1,000,000 n√≥s, 3,301,025 arestas.\n",
      "   Encontrando maior componente conectado...\n",
      "   üìä Grafo final (maior CC): 693,759 n√≥s, 3,301,024 arestas.\n",
      "   Ap√≥s construir grafo RAM Usada: 1,743.7 MB\n",
      "\n",
      "   üíæ Salvando grafo processado e labels para uso futuro...\n",
      "   ‚úÖ Arquivos salvos.\n",
      "   ‚Ü≥ Tempo total para carregar/construir grafo: 2036.53s\n",
      "\n",
      "üìà Grafo Carregado: 693,759 n√≥s, 3,301,024 arestas\n",
      "üéØ Bots Identificados: 81,431 (11.7%)\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Carregando/Construindo Grafo (Full Scale)...\")\n",
    "start_load = time.time()\n",
    "\n",
    "data_loader = TwiBotDataLoader()\n",
    "\n",
    "# Garantir que os diret√≥rios de cache existem\n",
    "cfg.create_dirs()\n",
    "\n",
    "# Passar max_nodes=None para carregar o grafo inteiro\n",
    "G, bot_labels = data_loader.load_and_build_graph(max_nodes=None)\n",
    "\n",
    "load_time = time.time() - start_load\n",
    "print(f\"   ‚Ü≥ Tempo total para carregar/construir grafo: {load_time:.2f}s\")\n",
    "print(f\"\\nüìà Grafo Carregado: {G.number_of_nodes():,} n√≥s, {G.number_of_edges():,} arestas\")\n",
    "print(f\"üéØ Bots Identificados: {sum(bot_labels.values()):,} ({sum(bot_labels.values())/len(bot_labels):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebi7cQRSebh7"
   },
   "source": [
    "## üß† Passo 3: Calcular Scores de Vi√©s (Full Scale)\n",
    "\n",
    "Esta √© a etapa computacionalmente mais intensiva. Ela ir√°:\n",
    "1.  Ler os arquivos de `/tmp/` (r√°pido).\n",
    "2.  Processar **todos** os tweets relevantes (sem limite artificial).\n",
    "3.  Usar todos os seus `NUM_WORKERS` e a A100.\n",
    "\n",
    "**Esta c√©lula levar√° um tempo consider√°vel (talvez horas), mas a barra de progresso `tqdm` mostrar√° o status.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwPL9_3pebh7",
    "outputId": "72e5b9a5-fd63-4360-c88c-f1ec6d43d345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Calculando/Carregando Scores de Vi√©s (Full Scale)...\n",
      "\n",
      "üß† Fase 2: Calculando/Carregando Scores de Vi√©s...\n",
      "   In√≠cio Vi√©s RAM Usada: 1,670.1 MB\n",
      "üíæ Verificando se o arquivo final 'c:\\Users\\axlsa\\Documents\\bias-aware-community-detection\\processed_data\\bias_scores.json' j√° existe...\n",
      "   Arquivo final n√£o encontrado. Calculando...\n",
      "\n",
      "--- Iniciando c√°lculo de scores de vi√©s (Single-Pass Paralelo) ---\n",
      "--- ATEN√á√ÉO WINDOWS: Lendo do caminho original c:\\Users\\axlsa\\Documents\\bias-aware-community-detection\\data\\TwiBot22 ---\n",
      "   (Caminho C:\\tmp\\tweet_data n√£o encontrado)\n",
      "\n",
      "--- Passagem √önica: Processando 2 arquivos em paralelo (12 workers) ---\n",
      "   Iniciando 2 workers. Acompanhe o progresso:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Progresso Workers: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [59:03<00:00, 1771.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Processamento paralelo conclu√≠do em 3543.89 segundos.\n",
      "   Ap√≥s processamento paralelo: RAM Usada: 19.4 MB\n",
      "\n",
      "‚öôÔ∏è Agregando resultados dos workers...\n",
      "   ‚Ü≥ Total de tweets processados: 0\n",
      "   ‚úÖ Agrega√ß√£o conclu√≠da em 3.05s para 0 usu√°rios.\n",
      "   Ap√≥s agrega√ß√£o: RAM Usada: 868.6 MB\n",
      "\n",
      "‚öôÔ∏è Calculando scores m√©dios de vi√©s por usu√°rio...\n",
      "\n",
      "‚öôÔ∏è Garantindo scores...\n",
      "   ‚Ü≥ 693,759 n√≥s sem tweets receberam score 0.0.\n",
      "\n",
      "üíæ Salvando scores finais em 'c:\\Users\\axlsa\\Documents\\bias-aware-community-detection\\processed_data\\bias_scores.json'...\n",
      "   ‚úÖ Scores finais salvos.\n",
      "\n",
      "‚úÖ C√°lculo de vi√©s (Completo) conclu√≠do.\n",
      "   Final: RAM Usada: 886.0 MB\n",
      "   ‚Ü≥ Tempo total para calcular/carregar vi√©s: 3549.23s\n",
      "‚ö†Ô∏è Dicion√°rio de vi√©s foi criado, mas est√° vazio ou s√≥ cont√©m zeros.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "print(\"üß† Calculando/Carregando Scores de Vi√©s (Full Scale)...\")\n",
    "start_bias = time.time()\n",
    "\n",
    "bias_calculator = BiasCalculator()\n",
    "\n",
    "# Esta fun√ß√£o agora est√° configurada para ler de /tmp/ e sem TWEET_LIMIT_PER_WORKER\n",
    "bias_scores = bias_calculator.get_or_calculate_bias_scores(set(G.nodes()))\n",
    "\n",
    "bias_time = time.time() - start_bias\n",
    "print(f\"   ‚Ü≥ Tempo total para calcular/carregar vi√©s: {bias_time:.2f}s\")\n",
    "\n",
    "# An√°lise explorat√≥ria dos scores reais\n",
    "if bias_scores:\n",
    "    bias_values = [s for s in bias_scores.values() if s != 0.0] # Ignorar n√≥s com 0.0 (sem tweets)\n",
    "    if bias_values:\n",
    "        print(f\"\\nüìä Estat√≠sticas do Vi√©s (N√≥s com tweets: {len(bias_values):,}):\")\n",
    "        print(f\"   M√©dia={np.mean(bias_values):.3f}, Std={np.std(bias_values):.3f}\")\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.hist(bias_values, bins=50, alpha=0.7, color='blue')\n",
    "        plt.title('Distribui√ß√£o dos Scores de Vi√©s (Dataset Completo)')\n",
    "        plt.xlabel('Score de Vi√©s (-1 Negativo, 1 Positivo)')\n",
    "        plt.ylabel('Frequ√™ncia')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Dicion√°rio de vi√©s foi criado, mas est√° vazio ou s√≥ cont√©m zeros.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nenhum score de vi√©s foi calculado ou carregado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryIw7r4oebh7"
   },
   "source": [
    "## üéØ Passo 4: Executar Heur√≠stica Corrigida (Enhanced Louvain)\n",
    "\n",
    "Executamos o algoritmo principal do artigo (a heur√≠stica corrigida) , usando `alpha=0.5` [cite: 18, 217] para balancear estrutura e vi√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "l1E71kYIebh7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Executando Enhanced Louvain com Vi√©s (Œ±=0.5)...\n",
      "üéØ Executando Enhanced Louvain (Œ±=0.5)...\n",
      "   Fase 1: Executando Louvain padr√£o para parti√ß√£o inicial...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m detector = EnhancedLouvainWithBias(alpha=cfg.ALPHA, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# O artigo foca em parti√ß√£o bin√°ria (k=2) [cite: 68-71, 99-106]\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mdetector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_communities\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m communities_enhanced = detector.get_communities()\n\u001b[32m     11\u001b[39m enhanced_time = time.time() - start_enhanced\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\axlsa\\Documents\\bias-aware-community-detection\\src\\heuristic.py:39\u001b[39m, in \u001b[36mEnhancedLouvainWithBias.fit\u001b[39m\u001b[34m(self, G, bias_scores, num_communities)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# 1. Obter parti√ß√£o inicial com Louvain padr√£o\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose: \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   Fase 1: Executando Louvain padr√£o para parti√ß√£o inicial...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m partition = \u001b[43mlouvain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbest_partition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRANDOM_STATE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# 2. Refinamento iterativo (O ALGORITMO DO ARTIGO)\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose: \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Fase 2: Iniciando refinamento iterativo (max_iter=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.max_iterations_refine\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\axlsa\\Documents\\bias-aware-community-detection\\.venv\\Lib\\site-packages\\community\\community_louvain.py:249\u001b[39m, in \u001b[36mbest_partition\u001b[39m\u001b[34m(graph, partition, weight, resolution, randomize, random_state)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbest_partition\u001b[39m(graph,\n\u001b[32m    164\u001b[39m                    partition=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    165\u001b[39m                    weight=\u001b[33m'\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    166\u001b[39m                    resolution=\u001b[32m1.\u001b[39m,\n\u001b[32m    167\u001b[39m                    randomize=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    168\u001b[39m                    random_state=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    169\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the partition of the graph nodes which maximises the modularity\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[33;03m    (or try..) using the Louvain heuristices\u001b[39;00m\n\u001b[32m    171\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m \u001b[33;03m    >>> plt.show()\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     dendo = \u001b[43mgenerate_dendrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mrandomize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m partition_at_level(dendo, \u001b[38;5;28mlen\u001b[39m(dendo) - \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\axlsa\\Documents\\bias-aware-community-detection\\.venv\\Lib\\site-packages\\community\\community_louvain.py:348\u001b[39m, in \u001b[36mgenerate_dendrogram\u001b[39m\u001b[34m(graph, part_init, weight, resolution, randomize, random_state)\u001b[39m\n\u001b[32m    345\u001b[39m         part[node] = i\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [part]\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m current_graph = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m status = Status()\n\u001b[32m    350\u001b[39m status.init(current_graph, weight, part_init)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\axlsa\\Documents\\bias-aware-community-detection\\.venv\\Lib\\site-packages\\networkx\\classes\\graph.py:1663\u001b[39m, in \u001b[36mGraph.copy\u001b[39m\u001b[34m(self, as_view)\u001b[39m\n\u001b[32m   1661\u001b[39m G.graph.update(\u001b[38;5;28mself\u001b[39m.graph)\n\u001b[32m   1662\u001b[39m G.add_nodes_from((n, d.copy()) \u001b[38;5;28;01mfor\u001b[39;00m n, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._node.items())\n\u001b[32m-> \u001b[39m\u001b[32m1663\u001b[39m \u001b[43mG\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_edges_from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1664\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatadict\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1665\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbrs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_adj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1666\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatadict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnbrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1667\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1668\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m G\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\axlsa\\Documents\\bias-aware-community-detection\\.venv\\Lib\\site-packages\\networkx\\classes\\graph.py:1049\u001b[39m, in \u001b[36mGraph.add_edges_from\u001b[39m\u001b[34m(self, ebunch_to_add, **attr)\u001b[39m\n\u001b[32m   1047\u001b[39m     \u001b[38;5;28mself\u001b[39m._adj[v] = \u001b[38;5;28mself\u001b[39m.adjlist_inner_dict_factory()\n\u001b[32m   1048\u001b[39m     \u001b[38;5;28mself\u001b[39m._node[v] = \u001b[38;5;28mself\u001b[39m.node_attr_dict_factory()\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m datadict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_adj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mu\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43medge_attr_dict_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1050\u001b[39m datadict.update(attr)\n\u001b[32m   1051\u001b[39m datadict.update(dd)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(f\"\\nüéØ Executando Enhanced Louvain com Vi√©s (Œ±={cfg.ALPHA})...\")\n",
    "start_enhanced = time.time()\n",
    "\n",
    "# Usar a classe HEURISTIC.PY corrigida\n",
    "detector = EnhancedLouvainWithBias(alpha=cfg.ALPHA, verbose=True)\n",
    "\n",
    "# O artigo foca em parti√ß√£o bin√°ria (k=2) [cite: 68-71, 99-106]\n",
    "detector.fit(G, bias_scores, num_communities=2)\n",
    "\n",
    "communities_enhanced = detector.get_communities()\n",
    "enhanced_time = time.time() - start_enhanced\n",
    "\n",
    "print(f\"\\n avaliando resultados da Heur√≠stica...\")\n",
    "metrics_enhanced = ComprehensiveEvaluator.evaluate_communities(\n",
    "    G, communities_enhanced, bias_scores, bot_labels\n",
    ")\n",
    "metrics_enhanced['runtime'] = enhanced_time\n",
    "\n",
    "print(f\"‚úÖ Heur√≠stica conclu√≠da em {enhanced_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTL6YVSRebh7"
   },
   "source": [
    "## ‚öñÔ∏è Passo 5: Executar Baseline (Louvain Padr√£o)\n",
    "\n",
    "Comparamos com o algoritmo de Louvain padr√£o, que otimiza apenas a modularidade (estrutura)[cite: 50]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6b6pky8ebh7"
   },
   "outputs": [],
   "source": [
    "print(\"\\n‚öñÔ∏è Executando Louvain Padr√£o (Baseline)...\")\n",
    "start_louvain = time.time()\n",
    "\n",
    "communities_louvain = louvain.best_partition(G, random_state=cfg.RANDOM_STATE)\n",
    "\n",
    "louvain_time = time.time() - start_louvain\n",
    "\n",
    "print(f\"... Louvain Padr√£o encontrou {len(set(communities_louvain.values()))} comunidades.\")\n",
    "print(\"   Avaliando resultados do Louvain Padr√£o...\")\n",
    "\n",
    "metrics_louvain = ComprehensiveEvaluator.evaluate_communities(\n",
    "    G, communities_louvain, bias_scores, bot_labels\n",
    ")\n",
    "metrics_louvain['runtime'] = louvain_time\n",
    "\n",
    "print(f\"‚úÖ Louvain Padr√£o conclu√≠do em {louvain_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnILl-B3ebh8"
   },
   "source": [
    "## üìà Passo 6: Resultados Finais e Compara√ß√£o\n",
    "\n",
    "Aqui vemos se o nosso m√©todo (Enhanced) supera o Baseline (Padr√£o) nas m√©tricas-chave do artigo: **Separa√ß√£o de Vi√©s** e **Pureza de Vi√©s** [cite: 136-138]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BtqJVAkebh8"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä RESULTADOS FINAIS (Full Scale TwiBot-22)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ComprehensiveEvaluator.print_comparison(\n",
    "    metrics_enhanced,\n",
    "    metrics_louvain,\n",
    "    \"Enhanced Louvain (Œ±=0.5)\",\n",
    "    \"Louvain Padr√£o (Œ±=0.0)\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- M√©tricas Detalhadas ---\")\n",
    "df_results = pd.DataFrame({\n",
    "    \"Enhanced Louvain (Œ±=0.5)\": metrics_enhanced,\n",
    "    \"Louvain Padr√£o (Œ±=0.0)\": metrics_louvain\n",
    "}).T\n",
    "\n",
    "print(df_results[['modularity', 'bias_separation', 'bias_purity', 'bot_concentration_max', 'num_communities', 'runtime']].to_markdown(floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTBT4v8Webh8"
   },
   "source": [
    "## üîç Passo 7: An√°lise Detalhada das Comunidades\n",
    "\n",
    "Vamos inspecionar as duas comunidades que nosso m√©todo encontrou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aufcNaRyebh8"
   },
   "outputs": [],
   "source": [
    "print(\"\\nüîç An√°lise Detalhada (Enhanced Louvain)\")\n",
    "\n",
    "comm_nodes_map = defaultdict(list)\n",
    "for node, comm in communities_enhanced.items():\n",
    "    comm_nodes_map[comm].append(node)\n",
    "\n",
    "for comm_id in sorted(comm_nodes_map.keys()):\n",
    "    comm_nodes = comm_nodes_map[comm_id]\n",
    "    comm_biases = [bias_scores.get(node, 0) for node in comm_nodes]\n",
    "    comm_bots = [bot_labels.get(node, False) for node in comm_nodes]\n",
    "\n",
    "    print(f\"\\nüè∑Ô∏è  Comunidade {comm_id}:\")\n",
    "    print(f\"   ‚Ä¢ {len(comm_nodes):,} n√≥s ({len(comm_nodes) / G.number_of_nodes():.1%})\")\n",
    "    print(f\"   ‚Ä¢ Vi√©s m√©dio: {np.mean(comm_biases):.3f} (¬±{np.std(comm_biases):.3f})\")\n",
    "    print(f\"   ‚Ä¢ Bots: {sum(comm_bots):,}/{len(comm_bots):,} ({sum(comm_bots)/len(comm_bots):.1%})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ EXPERIMENTO COMPLETO CONCLU√çDO!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
